{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94e11c2-f096-4835-a913-54fde624614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 21:15:46.475014: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762460146.496655     646 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762460146.502831     646 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1762460146.522110     646 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762460146.522132     646 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762460146.522134     646 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762460146.522136     646 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-06 21:15:46.530393: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Model, layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8c145a6-2a14-4a10-bd9c-734de29c7ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Convert to numpy float32\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "# Normalize data between 0 and 1\n",
    "#x_train, x_test = x_train/255, x_test/255\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test  = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "# splitting Data\n",
    "x_train, valid_data, y_train, valid_labels = train_test_split(\n",
    "    x_train, y_train,\n",
    "    test_size = 0.2,\n",
    "    random_state = 42,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c15af8d-c091-4711-b780-da86e673731b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762460153.015033     646 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Checking data\n",
    "if x_train.shape[1] != 32:\n",
    "    x_train = tf.pad(x_train, paddings=[[0, 0], [2, 2], [2, 2], [0, 0]], mode=\"CONSTANT\", constant_values=0)\n",
    "    valid_data = tf.pad(valid_data, paddings=[[0, 0], [2, 2], [2, 2], [0, 0]], mode=\"CONSTANT\", constant_values=0)\n",
    "    x_test = tf.pad(x_test, paddings=[[0, 0], [2, 2], [2, 2], [0, 0]], mode=\"CONSTANT\", constant_values=0)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "330fe0e8-6920-47b4-9648-ed2768b78634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "total_samples = len(x_train)\n",
    "num_classes = 10\n",
    "\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "epochs = 70\n",
    "steps_per_epoch = int(np.ceil(total_samples / batch_size))\n",
    "\n",
    "conv_layer1 = 6\n",
    "conv_layer2 = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07953a8-d1d0-453d-b115-9e98393219fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data batching, splitting and shuffle\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.shuffle(5000).repeat()\n",
    "\n",
    "\n",
    "train_data = train_data.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea54de6c-c99a-4788-a4b6-4fde376219a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Model\n",
    "class LeNet(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        mu=0,\n",
    "        sigma=0.01\n",
    "\n",
    "        # Convolutional Layer 1\n",
    "        self.w1 = tf.Variable(tf.random.normal([5, 5, 1, conv_layer1], mean=mu, stddev=sigma), name=\"weight1\", trainable=True)\n",
    "        self.b1 = tf.Variable(tf.zeros([conv_layer1]), name=\"bias1\", trainable=True)\n",
    "\n",
    "        # Convolutional Layer 2\n",
    "        self.w2 = tf.Variable(tf.random.normal([5, 5, conv_layer1, conv_layer2], mean=mu, stddev=sigma), name=\"weight2\", trainable=True)\n",
    "        self.b2 = tf.Variable(tf.zeros([conv_layer2]), name=\"bias2\", trainable=True)\n",
    "\n",
    "        # Fully connected layer 1\n",
    "        self.w3 = tf.Variable(tf.random.normal([5*5*conv_layer2, 120], mean=mu, stddev=sigma), name=\"weight3\", trainable=True)\n",
    "        self.b3 = tf.Variable(tf.zeros([120]), name=\"bias3\", trainable=True)\n",
    "\n",
    "        # Fully connected layer 2\n",
    "        self.w4 = tf.Variable(tf.random.normal([120, 84], mean=mu, stddev=sigma), name=\"weight4\", trainable=True)\n",
    "        self.b4 = tf.Variable(tf.zeros([84]), name=\"bias4\", trainable=True)\n",
    "\n",
    "        # Output Layer\n",
    "        self.w5 = tf.Variable(tf.random.normal([84, 10], mean=mu, stddev=sigma), name=\"weight5\", trainable=True)\n",
    "        self.b5 = tf.Variable(tf.zeros([10]), name=\"bias5\", trainable=True)\n",
    "\n",
    "        \n",
    "    def conv2d(self, x, filter_W, bias_conv, stride=2, padding=\"VALID\"):\n",
    "        conv_layer = tf.nn.conv2d(\n",
    "            x, filter_W,\n",
    "            strides = [1, stride, stride, 1],\n",
    "            padding = padding\n",
    "        )\n",
    "        conv_layer = tf.nn.bias_add(conv_layer, bias_conv)\n",
    "        conv_layer = tf.nn.relu(conv_layer)\n",
    "        return conv_layer\n",
    "\n",
    "    def maxpool2d(self, x, k=2, s=2):\n",
    "        return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, s, s, 1], padding=\"SAME\")\n",
    "    \n",
    "    def __call__(self, x, is_training=False):\n",
    "        keep_prob = 0.7\n",
    "        \n",
    "        # Layer 1\n",
    "        conv1 = self.conv2d(x, self.w1, self.b1, 1)\n",
    "        conv1 = self.maxpool2d(conv1, 2, 2)\n",
    "\n",
    "        # Layer 2\n",
    "        conv2 = self.conv2d(conv1, self.w2, self.b2, 1)\n",
    "        conv2 = self.maxpool2d(conv2, 2, 2)\n",
    "        conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "\n",
    "        # Flatten Layer \n",
    "        flatten = tf.reshape(conv2, [-1, self.w3.get_shape().as_list()[0]])\n",
    "\n",
    "        # Fully connected layer 1\n",
    "        fc1 = tf.nn.bias_add(tf.matmul(flatten, self.w3), self.b3)\n",
    "        fc1 = tf.nn.relu(fc1)\n",
    "        fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "        # Fullly connected layer 2\n",
    "        fc2 = tf.nn.bias_add(tf.matmul(fc1, self.w4), self.b4)\n",
    "        fc2 = tf.nn.relu(fc2)\n",
    "        fc1 = tf.nn.dropout(fc2, keep_prob)\n",
    "\n",
    "        # Output layer\n",
    "        out = tf.nn.bias_add(tf.matmul(fc2, self.w5), self.b5)\n",
    "\n",
    "        if not is_training:\n",
    "            return tf.nn.softmax(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3796678-ad0a-4339-93d8-4c62f0ac3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate)\n",
    "model = LeNet()\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "#checkpoint.save(\"./checkpoints/model\")\n",
    "manager = tf.train.CheckpointManager(checkpoint, \"./checkpoints\", max_to_keep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4578bc6d-45b7-4a3b-8750-52fc907fa1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(pred, y_true):\n",
    "    y_true = tf.cast(y_true, tf.int64)\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, logits=pred)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def accuracy(pred, y_true):\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40e89cc2-0686-466e-a36b-ddc4249952d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(X, Y):\n",
    "    with tf.GradientTape() as g:\n",
    "        logits = model(X, is_training=True)\n",
    "        loss = cross_entropy(logits, Y)\n",
    "\n",
    "    gradient = g.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7841c45e-d5c7-4b40-9e0c-8a8aa32856f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762307695.055588   84382 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-11-05 02:55:08.692128: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss 0.5101274847984314, train_accuracy 0.84375, validation_loss 0.501129686832428, validation_accuracy 0.8422499895095825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 02:55:21.665332: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train_loss 0.39101678133010864, train_accuracy 0.8671875, validation_loss 0.3663979172706604, validation_accuracy 0.8847500085830688\n",
      "Epoch 3, train_loss 0.3229140639305115, train_accuracy 0.91015625, validation_loss 0.30673208832740784, validation_accuracy 0.909166693687439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 02:55:46.496268: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train_loss 0.24450422823429108, train_accuracy 0.9296875, validation_loss 0.2854711413383484, validation_accuracy 0.9141666889190674\n",
      "Epoch 5, train_loss 0.3231094479560852, train_accuracy 0.8828125, validation_loss 0.2566177546977997, validation_accuracy 0.921750009059906\n",
      "Epoch 6, train_loss 0.22427837550640106, train_accuracy 0.9453125, validation_loss 0.24336589872837067, validation_accuracy 0.9276666641235352\n",
      "Epoch 7, train_loss 0.1837669461965561, train_accuracy 0.94921875, validation_loss 0.24360039830207825, validation_accuracy 0.9269166588783264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 02:56:36.383219: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, train_loss 0.1973298341035843, train_accuracy 0.9375, validation_loss 0.23515519499778748, validation_accuracy 0.9301666617393494\n",
      "Epoch 9, train_loss 0.2235563099384308, train_accuracy 0.9296875, validation_loss 0.23106753826141357, validation_accuracy 0.9353333115577698\n",
      "Epoch 10, train_loss 0.20833060145378113, train_accuracy 0.91796875, validation_loss 0.21093131601810455, validation_accuracy 0.9379166960716248\n",
      "Epoch 11, train_loss 0.16220347583293915, train_accuracy 0.94140625, validation_loss 0.2190445363521576, validation_accuracy 0.9356666803359985\n",
      "Epoch 12, train_loss 0.26020026206970215, train_accuracy 0.9375, validation_loss 0.2147841602563858, validation_accuracy 0.940416693687439\n",
      "Epoch 13, train_loss 0.19966155290603638, train_accuracy 0.9375, validation_loss 0.19743703305721283, validation_accuracy 0.9399166703224182\n",
      "Epoch 14, train_loss 0.2120639681816101, train_accuracy 0.9296875, validation_loss 0.2056165337562561, validation_accuracy 0.9393333196640015\n",
      "Epoch 15, train_loss 0.231267049908638, train_accuracy 0.921875, validation_loss 0.19980648159980774, validation_accuracy 0.9394999742507935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 02:58:15.943552: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, train_loss 0.26372891664505005, train_accuracy 0.9375, validation_loss 0.21827135980129242, validation_accuracy 0.9356666803359985\n",
      "Epoch 17, train_loss 0.13950099050998688, train_accuracy 0.95703125, validation_loss 0.19860273599624634, validation_accuracy 0.9424166679382324\n",
      "Epoch 18, train_loss 0.14343607425689697, train_accuracy 0.953125, validation_loss 0.18535999953746796, validation_accuracy 0.9453333616256714\n",
      "Epoch 19, train_loss 0.16334182024002075, train_accuracy 0.953125, validation_loss 0.1928251087665558, validation_accuracy 0.9441666603088379\n",
      "Epoch 20, train_loss 0.22053247690200806, train_accuracy 0.93359375, validation_loss 0.21433258056640625, validation_accuracy 0.9389166831970215\n",
      "Epoch 21, train_loss 0.09699929505586624, train_accuracy 0.97265625, validation_loss 0.19097131490707397, validation_accuracy 0.9483333230018616\n",
      "Epoch 22, train_loss 0.16631640493869781, train_accuracy 0.94140625, validation_loss 0.18343643844127655, validation_accuracy 0.9480833411216736\n",
      "Epoch 23, train_loss 0.17949463427066803, train_accuracy 0.95703125, validation_loss 0.189457967877388, validation_accuracy 0.9471666812896729\n",
      "Epoch 24, train_loss 0.15418751537799835, train_accuracy 0.94140625, validation_loss 0.18323995172977448, validation_accuracy 0.9473333358764648\n",
      "Epoch 25, train_loss 0.22526583075523376, train_accuracy 0.94140625, validation_loss 0.188100665807724, validation_accuracy 0.9448333382606506\n",
      "Epoch 26, train_loss 0.12082342803478241, train_accuracy 0.96875, validation_loss 0.20163576304912567, validation_accuracy 0.9415000081062317\n",
      "Epoch 27, train_loss 0.17743994295597076, train_accuracy 0.94921875, validation_loss 0.1886504590511322, validation_accuracy 0.9430000185966492\n",
      "Epoch 28, train_loss 0.16264265775680542, train_accuracy 0.94921875, validation_loss 0.19507953524589539, validation_accuracy 0.9431666731834412\n",
      "Epoch 29, train_loss 0.20174887776374817, train_accuracy 0.92578125, validation_loss 0.18662023544311523, validation_accuracy 0.9445000290870667\n",
      "Epoch 30, train_loss 0.17898230254650116, train_accuracy 0.9296875, validation_loss 0.185317724943161, validation_accuracy 0.9485833048820496\n",
      "Epoch 31, train_loss 0.09999136626720428, train_accuracy 0.96484375, validation_loss 0.18402862548828125, validation_accuracy 0.9456666707992554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 03:01:57.598610: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, train_loss 0.1616593301296234, train_accuracy 0.95703125, validation_loss 0.18028464913368225, validation_accuracy 0.9463333487510681\n",
      "Epoch 33, train_loss 0.2102922648191452, train_accuracy 0.9375, validation_loss 0.17720744013786316, validation_accuracy 0.9462500214576721\n",
      "Epoch 34, train_loss 0.16873976588249207, train_accuracy 0.95703125, validation_loss 0.18319739401340485, validation_accuracy 0.9483333230018616\n",
      "Epoch 35, train_loss 0.19837510585784912, train_accuracy 0.94140625, validation_loss 0.1704270988702774, validation_accuracy 0.9488333463668823\n",
      "Epoch 36, train_loss 0.19907930493354797, train_accuracy 0.94140625, validation_loss 0.17281949520111084, validation_accuracy 0.9482499957084656\n",
      "Epoch 37, train_loss 0.16142235696315765, train_accuracy 0.94921875, validation_loss 0.18384386599063873, validation_accuracy 0.9480833411216736\n",
      "Epoch 38, train_loss 0.14307866990566254, train_accuracy 0.9609375, validation_loss 0.1830686777830124, validation_accuracy 0.9460833072662354\n",
      "Epoch 39, train_loss 0.22757089138031006, train_accuracy 0.9375, validation_loss 0.17536169290542603, validation_accuracy 0.9480833411216736\n",
      "Epoch 40, train_loss 0.17397154867649078, train_accuracy 0.9453125, validation_loss 0.18587589263916016, validation_accuracy 0.9467499852180481\n",
      "Epoch 41, train_loss 0.12521937489509583, train_accuracy 0.9609375, validation_loss 0.17058555781841278, validation_accuracy 0.9495000243186951\n",
      "Epoch 42, train_loss 0.22520223259925842, train_accuracy 0.9375, validation_loss 0.1790904700756073, validation_accuracy 0.9483333230018616\n",
      "Epoch 43, train_loss 0.1025485172867775, train_accuracy 0.98046875, validation_loss 0.17224755883216858, validation_accuracy 0.949999988079071\n",
      "Epoch 44, train_loss 0.1806713044643402, train_accuracy 0.9375, validation_loss 0.17800875008106232, validation_accuracy 0.9508333206176758\n",
      "Epoch 45, train_loss 0.15881207585334778, train_accuracy 0.96875, validation_loss 0.174554243683815, validation_accuracy 0.9489166736602783\n",
      "Epoch 46, train_loss 0.10777687281370163, train_accuracy 0.96484375, validation_loss 0.17207245528697968, validation_accuracy 0.9489166736602783\n",
      "Epoch 47, train_loss 0.14608675241470337, train_accuracy 0.95703125, validation_loss 0.18779510259628296, validation_accuracy 0.9446666836738586\n",
      "Epoch 48, train_loss 0.11816070228815079, train_accuracy 0.9765625, validation_loss 0.17610551416873932, validation_accuracy 0.9490000009536743\n",
      "Epoch 49, train_loss 0.14496032893657684, train_accuracy 0.95703125, validation_loss 0.15473733842372894, validation_accuracy 0.953499972820282\n",
      "Epoch 50, train_loss 0.2242397964000702, train_accuracy 0.93359375, validation_loss 0.17933079600334167, validation_accuracy 0.9450833201408386\n",
      "Epoch 51, train_loss 0.12657849490642548, train_accuracy 0.96484375, validation_loss 0.17278191447257996, validation_accuracy 0.9484999775886536\n",
      "Epoch 52, train_loss 0.12549333274364471, train_accuracy 0.95703125, validation_loss 0.16567173600196838, validation_accuracy 0.9520833492279053\n",
      "Epoch 53, train_loss 0.15290609002113342, train_accuracy 0.94921875, validation_loss 0.16848210990428925, validation_accuracy 0.952750027179718\n",
      "Epoch 54, train_loss 0.11404340714216232, train_accuracy 0.96484375, validation_loss 0.16877736151218414, validation_accuracy 0.95291668176651\n",
      "Epoch 55, train_loss 0.18536101281642914, train_accuracy 0.92578125, validation_loss 0.16885162889957428, validation_accuracy 0.949833333492279\n",
      "Epoch 56, train_loss 0.169073224067688, train_accuracy 0.94921875, validation_loss 0.17238456010818481, validation_accuracy 0.9519166946411133\n",
      "Epoch 57, train_loss 0.15482059121131897, train_accuracy 0.953125, validation_loss 0.16265924274921417, validation_accuracy 0.9549166560173035\n",
      "Epoch 58, train_loss 0.09743979573249817, train_accuracy 0.97265625, validation_loss 0.15394127368927002, validation_accuracy 0.9545833468437195\n",
      "Epoch 59, train_loss 0.08705317974090576, train_accuracy 0.9765625, validation_loss 0.1747891902923584, validation_accuracy 0.9493333101272583\n",
      "Epoch 60, train_loss 0.14033864438533783, train_accuracy 0.9609375, validation_loss 0.16933326423168182, validation_accuracy 0.9520000219345093\n",
      "Epoch 61, train_loss 0.14641672372817993, train_accuracy 0.96875, validation_loss 0.17145219445228577, validation_accuracy 0.9487500190734863\n",
      "Epoch 62, train_loss 0.141927570104599, train_accuracy 0.95703125, validation_loss 0.16822701692581177, validation_accuracy 0.953416645526886\n",
      "Epoch 63, train_loss 0.18394598364830017, train_accuracy 0.9375, validation_loss 0.16967011988162994, validation_accuracy 0.950083315372467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 03:08:47.412295: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, train_loss 0.09359841793775558, train_accuracy 0.96484375, validation_loss 0.156622052192688, validation_accuracy 0.953249990940094\n",
      "Epoch 65, train_loss 0.20784251391887665, train_accuracy 0.9375, validation_loss 0.1624641716480255, validation_accuracy 0.9524999856948853\n",
      "Epoch 66, train_loss 0.23441541194915771, train_accuracy 0.921875, validation_loss 0.16498924791812897, validation_accuracy 0.9524999856948853\n",
      "Epoch 67, train_loss 0.11671153455972672, train_accuracy 0.96484375, validation_loss 0.16839270293712616, validation_accuracy 0.9520000219345093\n",
      "Epoch 68, train_loss 0.14976687729358673, train_accuracy 0.9453125, validation_loss 0.1907287985086441, validation_accuracy 0.9465000033378601\n",
      "Epoch 69, train_loss 0.14875608682632446, train_accuracy 0.95703125, validation_loss 0.1680448055267334, validation_accuracy 0.9524166584014893\n",
      "Epoch 70, train_loss 0.1387072503566742, train_accuracy 0.94921875, validation_loss 0.1528671532869339, validation_accuracy 0.9568333625793457\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    for step, (batch_X, batch_Y) in enumerate(train_data.take(steps_per_epoch), 1):\n",
    "        run_optimization(batch_X, batch_Y)\n",
    "\n",
    "    train_pred = model(batch_X, is_training=True)\n",
    "    train_loss = cross_entropy(train_pred, batch_Y)\n",
    "    train_acc = accuracy(train_pred, batch_Y)\n",
    "    valid_pred = model(valid_data, is_training=True)\n",
    "    valid_loss = cross_entropy(valid_pred, valid_labels)\n",
    "    valid_acc = accuracy(valid_pred, valid_labels)\n",
    "    manager.save()\n",
    "    #if epoch == 40:\n",
    "     #   learning_rate = 0.0005\n",
    "     #   optimizer = tf.optimizers.Adam(learning_rate)\n",
    "    #new_learning_rate = learning_rate * (0.95 ** epoch)\n",
    "    #optimizer.learning_rate.assign(new_learning_rate)\n",
    "\n",
    "    print(f\"Epoch {epoch}, train_loss {train_loss}, train_accuracy {train_acc}, validation_loss {valid_loss}, validation_accuracy {valid_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d99ddc6-004e-4f85-92fc-9b1818d7490c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 0.1400926113128662 Test accuracy 0.9595999717712402\n"
     ]
    }
   ],
   "source": [
    "test_pred = model(x_test, is_training=True)\n",
    "test_loss = cross_entropy(test_pred, y_test)\n",
    "test_acc = accuracy(test_pred, y_test)\n",
    "\n",
    "print(f\"Test loss {test_loss} Test accuracy {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ab3e103-11cf-4df1-8cbb-9257c263c24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e9a1ea7-9917-4c1d-902b-b6b5479c435a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=9596.0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc * len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f496c95a-b380-4685-be9b-7c266caee03a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
