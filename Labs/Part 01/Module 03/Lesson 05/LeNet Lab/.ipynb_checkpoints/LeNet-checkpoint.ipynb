{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94e11c2-f096-4835-a913-54fde624614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 09:29:37.260484: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762244977.277026    2411 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762244977.282141    2411 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1762244977.295564    2411 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762244977.295591    2411 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762244977.295594    2411 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762244977.295596    2411 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-04 09:29:37.302698: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Model, layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8c145a6-2a14-4a10-bd9c-734de29c7ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Convert to numpy float32\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "# Normalize data between 0 and 1\n",
    "x_train, x_test = x_train/255, x_test/255\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test  = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "\n",
    "# splitting Data\n",
    "x_train, valid_data, y_train, valid_labels = train_test_split(\n",
    "    x_train, y_train,\n",
    "    test_size = 0.25,\n",
    "    random_state = 42,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c15af8d-c091-4711-b780-da86e673731b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762244981.267424    2411 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Checking data\n",
    "if x_train.shape[1] != 32:\n",
    "    x_train = tf.pad(x_train, paddings=[[0, 0], [2, 2], [2, 2], [0, 0]], mode=\"CONSTANT\", constant_values=0)\n",
    "    valid_data = tf.pad(valid_data, paddings=[[0, 0], [2, 2], [2, 2], [0, 0]], mode=\"CONSTANT\", constant_values=0)\n",
    "    x_test = tf.pad(x_test, paddings=[[0, 0], [2, 2], [2, 2], [0, 0]], mode=\"CONSTANT\", constant_values=0)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "330fe0e8-6920-47b4-9648-ed2768b78634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "total_samples = len(x_train)\n",
    "\n",
    "train_size = int(0.75 * len(x_train))\n",
    "num_classes = 10\n",
    "\n",
    "batch_size = 125\n",
    "learning_rate = 0.001\n",
    "epochs = 50\n",
    "steps_per_epoch = int(np.ceil(total_samples / batch_size))\n",
    "\n",
    "conv_layer1 = 6\n",
    "conv_layer2 = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07953a8-d1d0-453d-b115-9e98393219fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data batching, splitting and shuffle\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.shuffle(5000).repeat()\n",
    "\n",
    "\n",
    "train_data = train_data.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea54de6c-c99a-4788-a4b6-4fde376219a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Model\n",
    "class LeNet(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # Convolutional Layer 1\n",
    "        self.w1 = tf.Variable(tf.random.normal([5, 5, 1, conv_layer1]), name=\"weight1\", trainable=True)\n",
    "        self.b1 = tf.Variable(tf.zeros([conv_layer1]), name=\"bias1\", trainable=True)\n",
    "\n",
    "        # Convolutional Layer 2\n",
    "        self.w2 = tf.Variable(tf.random.normal([5, 5, conv_layer1, conv_layer2]), name=\"weight2\", trainable=True)\n",
    "        self.b2 = tf.Variable(tf.zeros([conv_layer2]), name=\"bias2\", trainable=True)\n",
    "\n",
    "        # Fully connected layer 1\n",
    "        self.w3 = tf.Variable(tf.random.normal([5*5*conv_layer2, 120]), name=\"weight3\", trainable=True)\n",
    "        self.b3 = tf.Variable(tf.zeros([120]), name=\"bias3\", trainable=True)\n",
    "\n",
    "        # Fully connected layer 2\n",
    "        self.w4 = tf.Variable(tf.random.normal([120, 84]), name=\"weight4\", trainable=True)\n",
    "        self.b4 = tf.Variable(tf.zeros([84]), name=\"bias4\", trainable=True)\n",
    "\n",
    "        # Output Layer\n",
    "        self.w5 = tf.Variable(tf.random.normal([84, 10]), name=\"weight5\", trainable=True)\n",
    "        self.b5 = tf.Variable(tf.zeros([10]), name=\"bias5\", trainable=True)\n",
    "\n",
    "        \n",
    "    def conv2d(self, x, filter_W, bias_conv, stride=2, padding=\"VALID\"):\n",
    "        conv_layer = tf.nn.conv2d(\n",
    "            x, filter_W,\n",
    "            strides = [1, stride, stride, 1],\n",
    "            padding = padding\n",
    "        )\n",
    "        conv_layer = tf.nn.bias_add(conv_layer, bias_conv)\n",
    "        conv_layer = tf.nn.relu(conv_layer)\n",
    "        return conv_layer\n",
    "\n",
    "    def maxpool2d(self, x, k=2, s=2):\n",
    "        return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, s, s, 1], padding=\"SAME\")\n",
    "    \n",
    "    def __call__(self, x, is_training=False):\n",
    "        \n",
    "        # Layer 1\n",
    "        conv1 = self.conv2d(x, self.w1, self.b1, 1)\n",
    "        conv1 = self.maxpool2d(conv1, 2, 2)\n",
    "\n",
    "        # Layer 2\n",
    "        conv2 = self.conv2d(conv1, self.w2, self.b2, 1)\n",
    "        conv2 = self.maxpool2d(conv2, 2, 2)\n",
    "\n",
    "        # Flatten Layer \n",
    "        flatten = tf.reshape(conv2, [-1, self.w3.get_shape().as_list()[0]])\n",
    "\n",
    "        # Fully connected layer 1\n",
    "        fc1 = tf.nn.bias_add(tf.matmul(flatten, self.w3), self.b3)\n",
    "        fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "        # Fullly connected layer 2\n",
    "        fc2 = tf.nn.bias_add(tf.matmul(fc1, self.w4), self.b4)\n",
    "        fc2 = tf.nn.relu(fc2)\n",
    "\n",
    "        # Output layer\n",
    "        out = tf.nn.bias_add(tf.matmul(fc2, self.w5), self.b5)\n",
    "\n",
    "        if not is_training:\n",
    "            return tf.nn.softmax(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3796678-ad0a-4339-93d8-4c62f0ac3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate)\n",
    "model = LeNet()\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "#checkpoint.save(\"./checkpoints/model\")\n",
    "manager = tf.train.CheckpointManager(checkpoint, \"./checkpoints\", max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4578bc6d-45b7-4a3b-8750-52fc907fa1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(pred, y_true):\n",
    "    y_true = tf.cast(y_true, tf.int64)\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, logits=pred)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def accuracy(pred, y_true):\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40e89cc2-0686-466e-a36b-ddc4249952d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(X, Y):\n",
    "    with tf.GradientTape() as g:\n",
    "        logits = model(X, is_training=True)\n",
    "        loss = cross_entropy(logits, Y)\n",
    "\n",
    "    gradient = g.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7841c45e-d5c7-4b40-9e0c-8a8aa32856f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762244982.017099    2411 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-11-04 09:30:02.492943: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss 825.7679443359375, train_accuracy 0.6159999966621399, validation_loss 600.4097290039062, validation_accuracy 0.6962000131607056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 09:30:23.482459: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train_loss 382.82952880859375, train_accuracy 0.800000011920929, validation_loss 295.84063720703125, validation_accuracy 0.7914666533470154\n",
      "Epoch 3, train_loss 60.02098846435547, train_accuracy 0.871999979019165, validation_loss 195.51913452148438, validation_accuracy 0.837066650390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 09:31:04.464272: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train_loss 149.76126098632812, train_accuracy 0.8479999899864197, validation_loss 146.90780639648438, validation_accuracy 0.8628666400909424\n",
      "Epoch 5, train_loss 116.56695556640625, train_accuracy 0.8560000061988831, validation_loss 116.07823944091797, validation_accuracy 0.8809333443641663\n",
      "Epoch 6, train_loss 66.36398315429688, train_accuracy 0.8880000114440918, validation_loss 96.42884063720703, validation_accuracy 0.8915333151817322\n",
      "Epoch 7, train_loss 47.805335998535156, train_accuracy 0.9200000166893005, validation_loss 81.27116394042969, validation_accuracy 0.9017333388328552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 09:32:24.932638: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, train_loss 17.071176528930664, train_accuracy 0.9679999947547913, validation_loss 70.59456634521484, validation_accuracy 0.9079333543777466\n",
      "Epoch 9, train_loss 38.55482482910156, train_accuracy 0.9440000057220459, validation_loss 60.696632385253906, validation_accuracy 0.9170666933059692\n",
      "Epoch 10, train_loss 57.15888977050781, train_accuracy 0.9039999842643738, validation_loss 55.21232604980469, validation_accuracy 0.9220666885375977\n",
      "Epoch 11, train_loss 56.36164855957031, train_accuracy 0.9359999895095825, validation_loss 49.88028335571289, validation_accuracy 0.9243999719619751\n",
      "Epoch 12, train_loss 27.46620750427246, train_accuracy 0.9520000219345093, validation_loss 44.765254974365234, validation_accuracy 0.9287333488464355\n",
      "Epoch 13, train_loss 9.249762535095215, train_accuracy 0.9599999785423279, validation_loss 41.212284088134766, validation_accuracy 0.9311333298683167\n",
      "Epoch 14, train_loss 8.07313060760498, train_accuracy 0.9599999785423279, validation_loss 38.78728485107422, validation_accuracy 0.9318000078201294\n",
      "Epoch 15, train_loss 7.815770626068115, train_accuracy 0.9919999837875366, validation_loss 36.78751754760742, validation_accuracy 0.9341333508491516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 09:35:07.408918: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, train_loss 14.414636611938477, train_accuracy 0.9520000219345093, validation_loss 33.71027755737305, validation_accuracy 0.9390000104904175\n",
      "Epoch 17, train_loss 0.0, train_accuracy 1.0, validation_loss 32.13591384887695, validation_accuracy 0.9401999711990356\n",
      "Epoch 18, train_loss 3.2981796264648438, train_accuracy 0.9599999785423279, validation_loss 30.89787483215332, validation_accuracy 0.9395999908447266\n",
      "Epoch 19, train_loss 1.2071845531463623, train_accuracy 0.9919999837875366, validation_loss 30.59103775024414, validation_accuracy 0.9398666620254517\n",
      "Epoch 20, train_loss 1.6540263891220093, train_accuracy 0.9760000109672546, validation_loss 28.410232543945312, validation_accuracy 0.9418666958808899\n",
      "Epoch 21, train_loss 0.0, train_accuracy 1.0, validation_loss 28.00019073486328, validation_accuracy 0.9428666830062866\n",
      "Epoch 22, train_loss 0.08307936042547226, train_accuracy 0.9919999837875366, validation_loss 26.488161087036133, validation_accuracy 0.9453999996185303\n",
      "Epoch 23, train_loss 0.0, train_accuracy 1.0, validation_loss 25.928586959838867, validation_accuracy 0.9463333487510681\n",
      "Epoch 24, train_loss 1.9975587129592896, train_accuracy 0.9760000109672546, validation_loss 23.81546401977539, validation_accuracy 0.947866678237915\n",
      "Epoch 25, train_loss 0.8988637924194336, train_accuracy 0.984000027179718, validation_loss 23.938817977905273, validation_accuracy 0.949733316898346\n",
      "Epoch 26, train_loss 0.7430019378662109, train_accuracy 0.984000027179718, validation_loss 23.597625732421875, validation_accuracy 0.9502666592597961\n",
      "Epoch 27, train_loss 0.7369316220283508, train_accuracy 0.9919999837875366, validation_loss 23.298513412475586, validation_accuracy 0.9527333378791809\n",
      "Epoch 28, train_loss 0.0, train_accuracy 1.0, validation_loss 22.32647705078125, validation_accuracy 0.9524000287055969\n",
      "Epoch 29, train_loss 1.4854533672332764, train_accuracy 0.984000027179718, validation_loss 22.415332794189453, validation_accuracy 0.9526666402816772\n",
      "Epoch 30, train_loss 1.259927749633789, train_accuracy 0.9919999837875366, validation_loss 22.480093002319336, validation_accuracy 0.9513333439826965\n",
      "Epoch 31, train_loss 0.028087323531508446, train_accuracy 0.9919999837875366, validation_loss 21.507450103759766, validation_accuracy 0.9527999758720398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 09:41:26.972781: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, train_loss 1.167922854423523, train_accuracy 0.9919999837875366, validation_loss 20.893943786621094, validation_accuracy 0.9522666931152344\n",
      "Epoch 33, train_loss 6.6757173122766744e-09, train_accuracy 1.0, validation_loss 20.83713150024414, validation_accuracy 0.955133318901062\n",
      "Epoch 34, train_loss 0.2708750069141388, train_accuracy 0.9919999837875366, validation_loss 20.665388107299805, validation_accuracy 0.9562000036239624\n",
      "Epoch 35, train_loss 3.016010046005249, train_accuracy 0.984000027179718, validation_loss 20.26126480102539, validation_accuracy 0.9549999833106995\n",
      "Epoch 36, train_loss 0.0, train_accuracy 1.0, validation_loss 20.960037231445312, validation_accuracy 0.956333339214325\n",
      "Epoch 37, train_loss 1.1204922199249268, train_accuracy 0.9919999837875366, validation_loss 20.676420211791992, validation_accuracy 0.9564666748046875\n",
      "Epoch 38, train_loss 0.0, train_accuracy 1.0, validation_loss 19.844839096069336, validation_accuracy 0.9568666815757751\n",
      "Epoch 39, train_loss 0.719851553440094, train_accuracy 0.9919999837875366, validation_loss 20.19576644897461, validation_accuracy 0.9574000239372253\n",
      "Epoch 40, train_loss 0.0, train_accuracy 1.0, validation_loss 21.158571243286133, validation_accuracy 0.9567333459854126\n",
      "Epoch 41, train_loss 0.0, train_accuracy 1.0, validation_loss 20.289541244506836, validation_accuracy 0.9585333466529846\n",
      "Epoch 42, train_loss 0.0, train_accuracy 1.0, validation_loss 18.828052520751953, validation_accuracy 0.9595333337783813\n",
      "Epoch 43, train_loss 0.0, train_accuracy 1.0, validation_loss 19.717395782470703, validation_accuracy 0.9597333073616028\n",
      "Epoch 44, train_loss 0.0, train_accuracy 1.0, validation_loss 20.447086334228516, validation_accuracy 0.9585999846458435\n",
      "Epoch 45, train_loss 1.921445369720459, train_accuracy 0.9919999837875366, validation_loss 19.537494659423828, validation_accuracy 0.960266649723053\n",
      "Epoch 46, train_loss 0.0, train_accuracy 1.0, validation_loss 18.7784423828125, validation_accuracy 0.9593333601951599\n",
      "Epoch 47, train_loss 0.0, train_accuracy 1.0, validation_loss 19.24244499206543, validation_accuracy 0.9611333608627319\n",
      "Epoch 48, train_loss 0.0, train_accuracy 1.0, validation_loss 19.035018920898438, validation_accuracy 0.9621333479881287\n",
      "Epoch 49, train_loss 0.0, train_accuracy 1.0, validation_loss 19.084239959716797, validation_accuracy 0.961733341217041\n",
      "Epoch 50, train_loss 0.0, train_accuracy 1.0, validation_loss 18.196399688720703, validation_accuracy 0.9634666442871094\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    for step, (batch_X, batch_Y) in enumerate(train_data.take(steps_per_epoch), 1):\n",
    "        run_optimization(batch_X, batch_Y)\n",
    "\n",
    "    train_pred = model(batch_X, is_training=True)\n",
    "    train_loss = cross_entropy(train_pred, batch_Y)\n",
    "    train_acc = accuracy(train_pred, batch_Y)\n",
    "    valid_pred = model(valid_data, is_training=True)\n",
    "    valid_loss = cross_entropy(valid_pred, valid_labels)\n",
    "    valid_acc = accuracy(valid_pred, valid_labels)\n",
    "    manager.save()\n",
    "\n",
    "    print(f\"Epoch {epoch}, train_loss {train_loss}, train_accuracy {train_acc}, validation_loss {valid_loss}, validation_accuracy {valid_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d99ddc6-004e-4f85-92fc-9b1818d7490c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 15.48554801940918 Test accuracy 0.9657999873161316\n"
     ]
    }
   ],
   "source": [
    "test_pred = model(x_test, is_training=True)\n",
    "test_loss = cross_entropy(test_pred, y_test)\n",
    "test_acc = accuracy(test_pred, y_test)\n",
    "\n",
    "print(f\"Test loss {test_loss} Test accuracy {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ab3e103-11cf-4df1-8cbb-9257c263c24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e9a1ea7-9917-4c1d-902b-b6b5479c435a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=9289.0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc * len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f496c95a-b380-4685-be9b-7c266caee03a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
