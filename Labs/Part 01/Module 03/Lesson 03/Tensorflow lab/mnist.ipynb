{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "plLp_rJBvrtB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plLp_rJBvrtB",
    "outputId": "f62a3753-1530-482a-e863-bab41d4c7c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported.\n",
      "All files downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210001/210001 [00:49<00:00, 4271.56files/s]\n",
      "100%|██████████| 10001/10001 [00:01<00:00, 6174.27files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features and labels uncompressed.\n",
      "Tests Passed!\n",
      "Labels One-Hot Encoded\n",
      "Training features and labels randomized and split.\n",
      "Data cached in pickle file.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "\n",
    "print('All modules imported.')\n",
    "\n",
    "def download(url, file):\n",
    "    \"\"\"\n",
    "    Download file from <url>\n",
    "    :param url: URL to file\n",
    "    :param file: Local file path\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file):\n",
    "        print('Downloading ' + file + '...')\n",
    "        urlretrieve(url, file)\n",
    "        print('Download Finished')\n",
    "\n",
    "# Download the training and test dataset.\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_train.zip', 'notMNIST_train.zip')\n",
    "download('https://s3.amazonaws.com/udacity-sdc/notMNIST_test.zip', 'notMNIST_test.zip')\n",
    "\n",
    "# Make sure the files aren't corrupted\n",
    "assert hashlib.md5(open('notMNIST_train.zip', 'rb').read()).hexdigest() == 'c8673b3f28f489e9cdf3a3d74e2ac8fa',\\\n",
    "        'notMNIST_train.zip file is corrupted.  Remove the file and try again.'\n",
    "assert hashlib.md5(open('notMNIST_test.zip', 'rb').read()).hexdigest() == '5d3c7e653e63471c88df796156a9dfa9',\\\n",
    "        'notMNIST_test.zip file is corrupted.  Remove the file and try again.'\n",
    "\n",
    "# Wait until you see that all files have been downloaded.\n",
    "print('All files downloaded.')\n",
    "\n",
    "def uncompress_features_labels(file):\n",
    "    \"\"\"\n",
    "    Uncompress features and labels from a zip file\n",
    "    :param file: The zip file to extract the data from\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with ZipFile(file) as zipf:\n",
    "        # Progress Bar\n",
    "        filenames_pbar = tqdm(zipf.namelist(), unit='files')\n",
    "\n",
    "        # Get features and labels from all files\n",
    "        for filename in filenames_pbar:\n",
    "            # Check if the file is a directory\n",
    "            if not filename.endswith('/'):\n",
    "                with zipf.open(filename) as image_file:\n",
    "                    image = Image.open(image_file)\n",
    "                    image.load()\n",
    "                    # Load image data as 1 dimensional array\n",
    "                    # We're using float32 to save on memory space\n",
    "                    feature = np.array(image, dtype=np.float32).flatten()\n",
    "\n",
    "                # Get the the letter from the filename.  This is the letter of the image.\n",
    "                label = os.path.split(filename)[1][0]\n",
    "\n",
    "                features.append(feature)\n",
    "                labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Get the features and labels from the zip files\n",
    "train_features, train_labels = uncompress_features_labels('notMNIST_train.zip')\n",
    "test_features, test_labels = uncompress_features_labels('notMNIST_test.zip')\n",
    "\n",
    "# Limit the amount of data to work with a docker container\n",
    "docker_size_limit = 150000\n",
    "train_features, train_labels = resample(train_features, train_labels, n_samples=docker_size_limit)\n",
    "\n",
    "# Set flags for feature engineering.  This will prevent you from skipping an important step.\n",
    "is_features_normal = False\n",
    "is_labels_encod = False\n",
    "\n",
    "# Wait until you see that all features and labels have been uncompressed.\n",
    "print('All features and labels uncompressed.')\n",
    "\n",
    "# Problem 1 - Implement Min-Max scaling for grayscale image data\n",
    "def normalize_grayscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Min-Max scaling for grayscale image data\n",
    "    a, b = 0.1, 0.9\n",
    "    b_a = b - a\n",
    "    min_data = 0\n",
    "    max_data = 255\n",
    "    data_diff = max_data - min_data\n",
    "    return a + ((image_data - min_data) * b_a)/(max_data - min_data)\n",
    "\n",
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "# Test Cases\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 255])),\n",
    "    [0.1, 0.103137254902, 0.106274509804, 0.109411764706, 0.112549019608, 0.11568627451, 0.118823529412, 0.121960784314,\n",
    "     0.125098039216, 0.128235294118, 0.13137254902, 0.9],\n",
    "    decimal=3)\n",
    "np.testing.assert_array_almost_equal(\n",
    "    normalize_grayscale(np.array([0, 1, 10, 20, 30, 40, 233, 244, 254,255])),\n",
    "    [0.1, 0.103137254902, 0.13137254902, 0.162745098039, 0.194117647059, 0.225490196078, 0.830980392157, 0.865490196078,\n",
    "     0.896862745098, 0.9])\n",
    "\n",
    "if not is_features_normal:\n",
    "    train_features = normalize_grayscale(train_features)\n",
    "    test_features = normalize_grayscale(test_features)\n",
    "    is_features_normal = True\n",
    "\n",
    "print('Tests Passed!')\n",
    "\n",
    "if not is_labels_encod:\n",
    "    # Turn labels into numbers and apply One-Hot Encoding\n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(train_labels)\n",
    "    train_labels = encoder.transform(train_labels)\n",
    "    test_labels = encoder.transform(test_labels)\n",
    "\n",
    "    # Change to float32, so it can be multiplied against the features in TensorFlow, which are float32\n",
    "    train_labels = train_labels.astype(np.float32)\n",
    "    test_labels = test_labels.astype(np.float32)\n",
    "    is_labels_encod = True\n",
    "\n",
    "print('Labels One-Hot Encoded')\n",
    "\n",
    "assert is_features_normal, 'You skipped the step to normalize the features'\n",
    "assert is_labels_encod, 'You skipped the step to One-Hot Encode the labels'\n",
    "\n",
    "# Get randomized datasets for training and validation\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_size=0.05,\n",
    "    random_state=832289)\n",
    "\n",
    "print('Training features and labels randomized and split.')\n",
    "\n",
    "# Save the data for easy access\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open('notMNIST.pickle', 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'train_dataset': train_features,\n",
    "                    'train_labels': train_labels,\n",
    "                    'valid_dataset': valid_features,\n",
    "                    'valid_labels': valid_labels,\n",
    "                    'test_dataset': test_features,\n",
    "                    'test_labels': test_labels,\n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d08fe36-d4fa-4292-a54c-ccc02f156920",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d08fe36-d4fa-4292-a54c-ccc02f156920",
    "outputId": "70fb16dd-0856-4044-ab45-360ba0c7e724"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 11:20:13.790195: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762165213.817237   70288 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762165213.824945   70288 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1762165213.847821   70288 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762165213.847849   70288 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762165213.847851   70288 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762165213.847853   70288 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-03 11:20:13.856475: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and modules loaded.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load the modules\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reload the data\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  train_features = pickle_data['train_dataset']\n",
    "  train_labels = pickle_data['train_labels']\n",
    "  valid_features = pickle_data['valid_dataset']\n",
    "  valid_labels = pickle_data['valid_labels']\n",
    "  test_features = pickle_data['test_dataset']\n",
    "  test_labels = pickle_data['test_labels']\n",
    "  del pickle_data  # Free up memory\n",
    "\n",
    "\n",
    "print('Data and modules loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e49cb51f-2576-43b1-a76a-fa642597976d",
   "metadata": {
    "id": "e49cb51f-2576-43b1-a76a-fa642597976d"
   },
   "outputs": [],
   "source": [
    "# Data has been normalized\n",
    "total_samples = len(train_features)\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.003\n",
    "num_output = 10\n",
    "epochs = 200\n",
    "batch_size = 256\n",
    "steps_per_epoch = int(np.ceil(total_samples / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd74ff5-8247-4304-a21e-227e1dc40857",
   "metadata": {
    "id": "2dd74ff5-8247-4304-a21e-227e1dc40857"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762165223.877899   70288 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Cleaning Data\n",
    "#valid_labels, test_labels = np.array(valid_labels, np.int64), np.array(test_labels, np.int64)\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_features, train_labels))\n",
    "val_features, test_features = np.array(valid_features, np.float32), np.array(test_features, np.float32)\n",
    "\n",
    "# Data has been normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a9b1dc-03ab-4628-ac52-544a0540979a",
   "metadata": {
    "id": "52a9b1dc-03ab-4628-ac52-544a0540979a"
   },
   "outputs": [],
   "source": [
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa753673-88d7-4601-9dff-f9ade3381a24",
   "metadata": {
    "id": "aa753673-88d7-4601-9dff-f9ade3381a24"
   },
   "outputs": [],
   "source": [
    "features = train_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdc4dec7-5917-4ff5-941e-3d82566529ac",
   "metadata": {
    "id": "bdc4dec7-5917-4ff5-941e-3d82566529ac"
   },
   "outputs": [],
   "source": [
    "#W = tf.Variable(tf.random.normal([features, num_output], name=\"weights1\"))\n",
    "#B = tf.Variable(tf.zeros([num_output], name=\"bias1\"))\n",
    "\n",
    "W = {\n",
    "    \"w1\": tf.Variable(tf.random.normal([features, 512]), name=\"weight1\"),\n",
    "    \"w2\": tf.Variable(tf.random.normal([512, 128]), name=\"weight2\"),\n",
    "    \"w3\": tf.Variable(tf.random.normal([128, 32]), name=\"weight3\"),\n",
    "    \"out\": tf.Variable(tf.random.normal([32, num_output]), name=\"weight_out\")\n",
    "}\n",
    "\n",
    "B = {\n",
    "    \"b1\": tf.Variable(tf.zeros([512], name=\"bias1\")),\n",
    "    \"b2\": tf.Variable(tf.zeros([128], name=\"bias2\")),\n",
    "    \"b3\": tf.Variable(tf.zeros([32], name=\"bias3\")),\n",
    "    \"out\": tf.Variable(tf.zeros([num_output], name=\"bias_out\"))\n",
    "}\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "# Model\n",
    "class MyModel(tf.Module):\n",
    "    def __call__(self, X):\n",
    "      X = tf.add(tf.matmul(X, W[\"w1\"]), B[\"b1\"])\n",
    "      X = tf.nn.relu(X)\n",
    "      X = tf.add(tf.matmul(X, W[\"w2\"]), B[\"b2\"])\n",
    "      X = tf.nn.relu(X)\n",
    "      X = tf.add(tf.matmul(X, W[\"w3\"]), B[\"b3\"])\n",
    "      X = tf.nn.relu(X)\n",
    "      return tf.nn.softmax(tf.add(tf.matmul(X, W[\"out\"]), B[\"out\"]))\n",
    "\n",
    "def cross_entropy(y_pred, y_true):\n",
    "    # It has been one-hot encoded before storing as pickle\n",
    "    #y_true = tf.one_hot(y_true, depth=num_output)\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred), 1))\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    if len(y_true.shape) > 1 and y_true.shape[1] > 1:\n",
    "        y_true = tf.argmax(y_true, axis=1)\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "def run_optimizer(X, Y):\n",
    "    with tf.GradientTape() as g:\n",
    "        logit = model(X)\n",
    "        loss = cross_entropy(logit, Y)\n",
    "\n",
    "    trainable_variables = list(W.values()) + list(B.values())\n",
    "\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "    return None\n",
    "\n",
    "def batch_data(X, Y, batch_size):\n",
    "    output_data = []\n",
    "    sample_size = len(X)\n",
    "    for step in range(0, sample_size, batch_size):\n",
    "        start = batch_size * step\n",
    "        end = batch_size + start\n",
    "        batch_X = X[start:end]\n",
    "        batch_Y = Y[start:end]\n",
    "        yield batch_X, batch_Y\n",
    "\n",
    "model=MyModel()\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(model = model)\n",
    "checkpoint.save(\"./checkpoints/mymodel\")\n",
    "manager = tf.train.CheckpointManager(checkpoint, \"./checkpoints\", max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eed6bd8f-4bdc-4110-8cec-91ba172b3b55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eed6bd8f-4bdc-4110-8cec-91ba172b3b55",
    "outputId": "5401ecb4-0c4f-4044-8018-1bef1925c762"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 11:20:41.345619: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train_loss 15.9472017288208, train_accuracy 0.23046875, val_loss 16.08010482788086, val_accuracy 0.22360000014305115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 11:20:55.063255: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, train_loss 14.894847869873047, train_accuracy 0.28125, val_loss 15.113365173339844, val_accuracy 0.27026665210723877\n",
      "Epoch: 3, train_loss 14.89484977722168, train_accuracy 0.28125, val_loss 14.618520736694336, val_accuracy 0.29413333535194397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 11:21:20.838429: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, train_loss 14.651996612548828, train_accuracy 0.29296875, val_loss 14.407341957092285, val_accuracy 0.30453333258628845\n",
      "Epoch: 5, train_loss 13.680593490600586, train_accuracy 0.33984375, val_loss 14.124927520751953, val_accuracy 0.31839999556541443\n",
      "Epoch: 6, train_loss 13.437743186950684, train_accuracy 0.3515625, val_loss 14.18721866607666, val_accuracy 0.3153333365917206\n",
      "Epoch: 7, train_loss 14.166296005249023, train_accuracy 0.31640625, val_loss 14.310124397277832, val_accuracy 0.30906665325164795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 11:22:14.091526: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, train_loss 14.004395484924316, train_accuracy 0.32421875, val_loss 14.245406150817871, val_accuracy 0.31253331899642944\n",
      "Epoch: 9, train_loss 13.680593490600586, train_accuracy 0.33984375, val_loss 14.015146255493164, val_accuracy 0.3234666585922241\n",
      "Epoch: 10, train_loss 14.651997566223145, train_accuracy 0.29296875, val_loss 14.142412185668945, val_accuracy 0.3173333406448364\n",
      "Epoch: 11, train_loss 14.328195571899414, train_accuracy 0.30859375, val_loss 13.907259941101074, val_accuracy 0.3287999927997589\n",
      "Epoch: 12, train_loss 13.59964370727539, train_accuracy 0.34375, val_loss 14.006645202636719, val_accuracy 0.3240000009536743\n",
      "Epoch: 13, train_loss 15.299598693847656, train_accuracy 0.26171875, val_loss 14.239992141723633, val_accuracy 0.31253331899642944\n",
      "Epoch: 14, train_loss 14.975797653198242, train_accuracy 0.27734375, val_loss 14.228572845458984, val_accuracy 0.31333333253860474\n",
      "Epoch: 15, train_loss 13.518693923950195, train_accuracy 0.34765625, val_loss 13.732144355773926, val_accuracy 0.33719998598098755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 11:23:58.204313: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, train_loss 13.761545181274414, train_accuracy 0.3359375, val_loss 13.735458374023438, val_accuracy 0.3370666801929474\n",
      "Epoch: 17, train_loss 13.680593490600586, train_accuracy 0.33984375, val_loss 13.749789237976074, val_accuracy 0.33640000224113464\n",
      "Epoch: 18, train_loss 14.571045875549316, train_accuracy 0.296875, val_loss 13.892918586730957, val_accuracy 0.32946667075157166\n",
      "Epoch: 19, train_loss 14.732948303222656, train_accuracy 0.2890625, val_loss 13.866809844970703, val_accuracy 0.33079999685287476\n",
      "Epoch: 20, train_loss 14.571046829223633, train_accuracy 0.296875, val_loss 13.790643692016602, val_accuracy 0.33453333377838135\n",
      "Epoch: 21, train_loss 14.651998519897461, train_accuracy 0.29296875, val_loss 13.677927017211914, val_accuracy 0.33986666798591614\n",
      "Epoch: 22, train_loss 12.952041625976562, train_accuracy 0.375, val_loss 13.697990417480469, val_accuracy 0.3389333188533783\n",
      "Epoch: 23, train_loss 14.490097045898438, train_accuracy 0.30078125, val_loss 13.638165473937988, val_accuracy 0.34173333644866943\n",
      "Epoch: 24, train_loss 13.923445701599121, train_accuracy 0.328125, val_loss 13.821064949035645, val_accuracy 0.3330666720867157\n",
      "Epoch: 25, train_loss 12.628240585327148, train_accuracy 0.390625, val_loss 13.619331359863281, val_accuracy 0.34279999136924744\n",
      "Epoch: 26, train_loss 14.571046829223633, train_accuracy 0.296875, val_loss 13.583410263061523, val_accuracy 0.3445333242416382\n",
      "Epoch: 27, train_loss 14.490096092224121, train_accuracy 0.30078125, val_loss 13.658014297485352, val_accuracy 0.34093332290649414\n",
      "Epoch: 28, train_loss 14.166295051574707, train_accuracy 0.31640625, val_loss 14.050374984741211, val_accuracy 0.32199999690055847\n",
      "Epoch: 29, train_loss 14.004396438598633, train_accuracy 0.32421875, val_loss 13.633705139160156, val_accuracy 0.34200000762939453\n",
      "Epoch: 30, train_loss 13.032991409301758, train_accuracy 0.37109375, val_loss 13.954862594604492, val_accuracy 0.32653334736824036\n",
      "Epoch: 31, train_loss 14.085346221923828, train_accuracy 0.3203125, val_loss 13.641926765441895, val_accuracy 0.3416000008583069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 11:27:12.130216: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, train_loss 14.490096092224121, train_accuracy 0.30078125, val_loss 14.156024932861328, val_accuracy 0.3166666626930237\n",
      "Epoch: 33, train_loss 14.004393577575684, train_accuracy 0.32421875, val_loss 13.67917537689209, val_accuracy 0.3397333323955536\n",
      "Epoch: 34, train_loss 14.085344314575195, train_accuracy 0.3203125, val_loss 13.649806022644043, val_accuracy 0.34119999408721924\n",
      "Epoch: 35, train_loss 14.813896179199219, train_accuracy 0.28515625, val_loss 13.75751781463623, val_accuracy 0.33613333106040955\n",
      "Epoch: 36, train_loss 14.409146308898926, train_accuracy 0.3046875, val_loss 13.68655014038086, val_accuracy 0.33933332562446594\n",
      "Epoch: 37, train_loss 13.680593490600586, train_accuracy 0.33984375, val_loss 13.55478572845459, val_accuracy 0.3457333445549011\n",
      "Epoch: 38, train_loss 14.00439453125, train_accuracy 0.32421875, val_loss 13.586287498474121, val_accuracy 0.3442666530609131\n",
      "Epoch: 39, train_loss 12.790142059326172, train_accuracy 0.3828125, val_loss 13.581897735595703, val_accuracy 0.34439998865127563\n",
      "Epoch: 40, train_loss 14.32819652557373, train_accuracy 0.30859375, val_loss 13.530943870544434, val_accuracy 0.3470666706562042\n",
      "Epoch: 41, train_loss 13.761543273925781, train_accuracy 0.3359375, val_loss 13.655967712402344, val_accuracy 0.3407999873161316\n",
      "Epoch: 42, train_loss 14.490096092224121, train_accuracy 0.30078125, val_loss 14.055349349975586, val_accuracy 0.3215999901294708\n",
      "Epoch: 43, train_loss 13.761545181274414, train_accuracy 0.3359375, val_loss 13.541419982910156, val_accuracy 0.34653332829475403\n",
      "Epoch: 44, train_loss 14.57104778289795, train_accuracy 0.296875, val_loss 13.567366600036621, val_accuracy 0.3452000021934509\n",
      "Epoch: 45, train_loss 13.113943099975586, train_accuracy 0.3671875, val_loss 13.635909080505371, val_accuracy 0.34200000762939453\n",
      "Epoch: 46, train_loss 14.328195571899414, train_accuracy 0.30859375, val_loss 13.562114715576172, val_accuracy 0.345466673374176\n",
      "Epoch: 47, train_loss 14.166295051574707, train_accuracy 0.31640625, val_loss 13.608001708984375, val_accuracy 0.34333333373069763\n",
      "Epoch: 48, train_loss 13.59964370727539, train_accuracy 0.34375, val_loss 13.494990348815918, val_accuracy 0.34880000352859497\n",
      "Epoch: 49, train_loss 14.166296005249023, train_accuracy 0.31640625, val_loss 13.774534225463867, val_accuracy 0.3352000117301941\n",
      "Epoch: 50, train_loss 14.166296005249023, train_accuracy 0.31640625, val_loss 13.732720375061035, val_accuracy 0.33719998598098755\n",
      "Epoch: 51, train_loss 13.599642753601074, train_accuracy 0.34375, val_loss 13.507610321044922, val_accuracy 0.3481333255767822\n",
      "Epoch: 52, train_loss 14.651996612548828, train_accuracy 0.29296875, val_loss 13.558609008789062, val_accuracy 0.3457333445549011\n",
      "Epoch: 53, train_loss 14.166296005249023, train_accuracy 0.31640625, val_loss 13.531461715698242, val_accuracy 0.3467999994754791\n",
      "Epoch: 54, train_loss 12.466340065002441, train_accuracy 0.3984375, val_loss 13.486246109008789, val_accuracy 0.3492000102996826\n",
      "Epoch: 55, train_loss 14.571046829223633, train_accuracy 0.296875, val_loss 13.522622108459473, val_accuracy 0.34746667742729187\n",
      "Epoch: 56, train_loss 14.651996612548828, train_accuracy 0.29296875, val_loss 13.558318138122559, val_accuracy 0.3456000089645386\n",
      "Epoch: 57, train_loss 14.247245788574219, train_accuracy 0.3125, val_loss 13.617912292480469, val_accuracy 0.34279999136924744\n",
      "Epoch: 58, train_loss 14.004395484924316, train_accuracy 0.32421875, val_loss 13.578014373779297, val_accuracy 0.34466665983200073\n",
      "Epoch: 59, train_loss 13.680593490600586, train_accuracy 0.33984375, val_loss 13.524858474731445, val_accuracy 0.3472000062465668\n",
      "Epoch: 60, train_loss 13.518693923950195, train_accuracy 0.34765625, val_loss 13.544727325439453, val_accuracy 0.3463999927043915\n",
      "Epoch: 61, train_loss 12.466341018676758, train_accuracy 0.3984375, val_loss 13.497786521911621, val_accuracy 0.3486666679382324\n",
      "Epoch: 62, train_loss 14.247246742248535, train_accuracy 0.3125, val_loss 13.561262130737305, val_accuracy 0.3456000089645386\n",
      "Epoch: 63, train_loss 14.247246742248535, train_accuracy 0.3125, val_loss 13.521829605102539, val_accuracy 0.34746667742729187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 11:33:11.199350: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64, train_loss 14.247245788574219, train_accuracy 0.3125, val_loss 13.500679969787598, val_accuracy 0.3482666611671448\n",
      "Epoch: 65, train_loss 12.304438591003418, train_accuracy 0.40625, val_loss 13.582154273986816, val_accuracy 0.3445333242416382\n",
      "Epoch: 66, train_loss 14.00439453125, train_accuracy 0.32421875, val_loss 13.486298561096191, val_accuracy 0.34906667470932007\n",
      "Epoch: 67, train_loss 13.275843620300293, train_accuracy 0.359375, val_loss 13.531766891479492, val_accuracy 0.3469333350658417\n",
      "Epoch: 68, train_loss 13.27584171295166, train_accuracy 0.359375, val_loss 13.591699600219727, val_accuracy 0.3441333472728729\n",
      "Epoch: 69, train_loss 13.59964370727539, train_accuracy 0.34375, val_loss 13.50054931640625, val_accuracy 0.3485333323478699\n",
      "Epoch: 70, train_loss 14.32819652557373, train_accuracy 0.30859375, val_loss 13.526128768920898, val_accuracy 0.3472000062465668\n",
      "Epoch: 71, train_loss 13.761543273925781, train_accuracy 0.3359375, val_loss 13.673370361328125, val_accuracy 0.3400000035762787\n",
      "Epoch: 72, train_loss 15.218648910522461, train_accuracy 0.265625, val_loss 13.492228507995605, val_accuracy 0.3489333391189575\n",
      "Epoch: 73, train_loss 13.032991409301758, train_accuracy 0.37109375, val_loss 13.533675193786621, val_accuracy 0.3469333350658417\n",
      "Epoch: 74, train_loss 13.032991409301758, train_accuracy 0.37109375, val_loss 13.536438941955566, val_accuracy 0.3467999994754791\n",
      "Epoch: 75, train_loss 14.32819652557373, train_accuracy 0.30859375, val_loss 13.534342765808105, val_accuracy 0.3467999994754791\n",
      "Epoch: 76, train_loss 14.00439453125, train_accuracy 0.32421875, val_loss 13.58341121673584, val_accuracy 0.3445333242416382\n",
      "Epoch: 77, train_loss 12.547290802001953, train_accuracy 0.39453125, val_loss 13.571264266967773, val_accuracy 0.3450666666030884\n",
      "Epoch: 78, train_loss 13.923443794250488, train_accuracy 0.328125, val_loss 13.497806549072266, val_accuracy 0.3486666679382324\n",
      "Epoch: 79, train_loss 13.680595397949219, train_accuracy 0.33984375, val_loss 13.483939170837402, val_accuracy 0.34933334589004517\n",
      "Epoch: 80, train_loss 14.247246742248535, train_accuracy 0.3125, val_loss 13.663556098937988, val_accuracy 0.34066668152809143\n",
      "Epoch: 81, train_loss 13.194892883300781, train_accuracy 0.36328125, val_loss 13.63493537902832, val_accuracy 0.34200000762939453\n",
      "Epoch: 82, train_loss 13.680593490600586, train_accuracy 0.33984375, val_loss 13.566831588745117, val_accuracy 0.3453333377838135\n",
      "Epoch: 83, train_loss 14.166296005249023, train_accuracy 0.31640625, val_loss 13.457639694213867, val_accuracy 0.35040000081062317\n",
      "Epoch: 84, train_loss 13.518693923950195, train_accuracy 0.34765625, val_loss 13.468467712402344, val_accuracy 0.349866658449173\n",
      "Epoch: 85, train_loss 13.680595397949219, train_accuracy 0.33984375, val_loss 13.47412109375, val_accuracy 0.3497333228588104\n",
      "Epoch: 86, train_loss 13.680593490600586, train_accuracy 0.33984375, val_loss 13.333627700805664, val_accuracy 0.3564000129699707\n",
      "Epoch: 87, train_loss 10.847333908081055, train_accuracy 0.4765625, val_loss 12.64493465423584, val_accuracy 0.38973334431648254\n",
      "Epoch: 88, train_loss 11.333036422729492, train_accuracy 0.453125, val_loss 12.293947219848633, val_accuracy 0.40666666626930237\n",
      "Epoch: 89, train_loss 12.628241539001465, train_accuracy 0.390625, val_loss 12.45053768157959, val_accuracy 0.3991999924182892\n",
      "Epoch: 90, train_loss 13.356792449951172, train_accuracy 0.35546875, val_loss 12.446701049804688, val_accuracy 0.39933332800865173\n",
      "Epoch: 91, train_loss 12.223489761352539, train_accuracy 0.41015625, val_loss 12.437397956848145, val_accuracy 0.3997333347797394\n",
      "Epoch: 92, train_loss 12.466341018676758, train_accuracy 0.3984375, val_loss 12.331757545471191, val_accuracy 0.4049333333969116\n",
      "Epoch: 93, train_loss 12.709190368652344, train_accuracy 0.38671875, val_loss 12.401531219482422, val_accuracy 0.4013333320617676\n",
      "Epoch: 94, train_loss 12.466341018676758, train_accuracy 0.3984375, val_loss 12.390170097351074, val_accuracy 0.4020000100135803\n",
      "Epoch: 95, train_loss 12.223489761352539, train_accuracy 0.41015625, val_loss 12.334468841552734, val_accuracy 0.4046666622161865\n",
      "Epoch: 96, train_loss 11.009235382080078, train_accuracy 0.46875, val_loss 12.182518005371094, val_accuracy 0.4121333360671997\n",
      "Epoch: 97, train_loss 11.575887680053711, train_accuracy 0.44140625, val_loss 12.071147918701172, val_accuracy 0.4174666702747345\n",
      "Epoch: 98, train_loss 10.928285598754883, train_accuracy 0.47265625, val_loss 12.241765022277832, val_accuracy 0.40906667709350586\n",
      "Epoch: 99, train_loss 13.842494010925293, train_accuracy 0.33203125, val_loss 12.179905891418457, val_accuracy 0.41226667165756226\n",
      "Epoch: 100, train_loss 12.304439544677734, train_accuracy 0.40625, val_loss 12.005009651184082, val_accuracy 0.42053332924842834\n",
      "Epoch: 101, train_loss 12.223489761352539, train_accuracy 0.41015625, val_loss 12.006109237670898, val_accuracy 0.42053332924842834\n",
      "Epoch: 102, train_loss 12.061590194702148, train_accuracy 0.41796875, val_loss 11.898674964904785, val_accuracy 0.4257333278656006\n",
      "Epoch: 103, train_loss 11.656837463378906, train_accuracy 0.4375, val_loss 12.02292537689209, val_accuracy 0.41973334550857544\n",
      "Epoch: 104, train_loss 12.061588287353516, train_accuracy 0.41796875, val_loss 11.953180313110352, val_accuracy 0.42320001125335693\n",
      "Epoch: 105, train_loss 12.547290802001953, train_accuracy 0.39453125, val_loss 11.952404022216797, val_accuracy 0.4230666756629944\n",
      "Epoch: 106, train_loss 11.413987159729004, train_accuracy 0.44921875, val_loss 11.953967094421387, val_accuracy 0.4230666756629944\n",
      "Epoch: 107, train_loss 11.81873893737793, train_accuracy 0.4296875, val_loss 12.040575981140137, val_accuracy 0.4187999963760376\n",
      "Epoch: 108, train_loss 11.899687767028809, train_accuracy 0.42578125, val_loss 11.908119201660156, val_accuracy 0.42533332109451294\n",
      "Epoch: 109, train_loss 11.656837463378906, train_accuracy 0.4375, val_loss 11.848664283752441, val_accuracy 0.4281333386898041\n",
      "Epoch: 110, train_loss 12.142539024353027, train_accuracy 0.4140625, val_loss 11.904512405395508, val_accuracy 0.4254666566848755\n",
      "Epoch: 111, train_loss 11.899688720703125, train_accuracy 0.42578125, val_loss 11.871345520019531, val_accuracy 0.4270666539669037\n",
      "Epoch: 112, train_loss 11.09018611907959, train_accuracy 0.46484375, val_loss 11.864760398864746, val_accuracy 0.42746666073799133\n",
      "Epoch: 113, train_loss 10.847333908081055, train_accuracy 0.4765625, val_loss 11.462146759033203, val_accuracy 0.44679999351501465\n",
      "Epoch: 114, train_loss 11.09018611907959, train_accuracy 0.46484375, val_loss 10.314979553222656, val_accuracy 0.5019999742507935\n",
      "Epoch: 115, train_loss 8.985479354858398, train_accuracy 0.56640625, val_loss 9.75458812713623, val_accuracy 0.52920001745224\n",
      "Epoch: 116, train_loss 9.714031219482422, train_accuracy 0.53125, val_loss 9.594756126403809, val_accuracy 0.5368000268936157\n",
      "Epoch: 117, train_loss 8.985479354858398, train_accuracy 0.56640625, val_loss 9.297450065612793, val_accuracy 0.5511999726295471\n",
      "Epoch: 118, train_loss 10.36163330078125, train_accuracy 0.5, val_loss 9.334278106689453, val_accuracy 0.5494666695594788\n",
      "Epoch: 119, train_loss 9.147378921508789, train_accuracy 0.55859375, val_loss 9.386337280273438, val_accuracy 0.5464000105857849\n",
      "Epoch: 120, train_loss 8.985479354858398, train_accuracy 0.56640625, val_loss 9.309845924377441, val_accuracy 0.5504000186920166\n",
      "Epoch: 121, train_loss 9.552130699157715, train_accuracy 0.5390625, val_loss 9.349791526794434, val_accuracy 0.5486666560173035\n",
      "Epoch: 122, train_loss 8.985479354858398, train_accuracy 0.56640625, val_loss 9.34619140625, val_accuracy 0.5486666560173035\n",
      "Epoch: 123, train_loss 9.875931739807129, train_accuracy 0.5234375, val_loss 9.035606384277344, val_accuracy 0.5637333393096924\n",
      "Epoch: 124, train_loss 10.118782997131348, train_accuracy 0.51171875, val_loss 9.697349548339844, val_accuracy 0.5318666696548462\n",
      "Epoch: 125, train_loss 9.147379875183105, train_accuracy 0.55859375, val_loss 9.290599822998047, val_accuracy 0.5514666438102722\n",
      "Epoch: 126, train_loss 9.633081436157227, train_accuracy 0.53515625, val_loss 9.38497257232666, val_accuracy 0.5469333529472351\n",
      "Epoch: 127, train_loss 8.33787727355957, train_accuracy 0.59765625, val_loss 9.134592056274414, val_accuracy 0.5589333176612854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 11:44:02.116601: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 128, train_loss 8.499776840209961, train_accuracy 0.58984375, val_loss 9.562102317810059, val_accuracy 0.5385333299636841\n",
      "Epoch: 129, train_loss 10.604484558105469, train_accuracy 0.48828125, val_loss 10.402511596679688, val_accuracy 0.4975999891757965\n",
      "Epoch: 130, train_loss 9.875931739807129, train_accuracy 0.5234375, val_loss 9.039019584655762, val_accuracy 0.5634666681289673\n",
      "Epoch: 131, train_loss 9.95688247680664, train_accuracy 0.51953125, val_loss 9.010406494140625, val_accuracy 0.5650666952133179\n",
      "Epoch: 132, train_loss 10.604484558105469, train_accuracy 0.48828125, val_loss 9.513537406921387, val_accuracy 0.5405333042144775\n",
      "Epoch: 133, train_loss 9.552130699157715, train_accuracy 0.5390625, val_loss 9.147262573242188, val_accuracy 0.5583999752998352\n",
      "Epoch: 134, train_loss 9.309280395507812, train_accuracy 0.55078125, val_loss 9.01533317565918, val_accuracy 0.5646666884422302\n",
      "Epoch: 135, train_loss 10.36163330078125, train_accuracy 0.5, val_loss 9.009541511535645, val_accuracy 0.5650666952133179\n",
      "Epoch: 136, train_loss 9.714031219482422, train_accuracy 0.53125, val_loss 9.050657272338867, val_accuracy 0.5631999969482422\n",
      "Epoch: 137, train_loss 9.2283296585083, train_accuracy 0.5546875, val_loss 9.068975448608398, val_accuracy 0.5621333122253418\n",
      "Epoch: 138, train_loss 8.823577880859375, train_accuracy 0.57421875, val_loss 8.983002662658691, val_accuracy 0.5661333203315735\n",
      "Epoch: 139, train_loss 10.36163330078125, train_accuracy 0.5, val_loss 9.091609954833984, val_accuracy 0.5612000226974487\n",
      "Epoch: 140, train_loss 8.175975799560547, train_accuracy 0.60546875, val_loss 9.030447006225586, val_accuracy 0.56413334608078\n",
      "Epoch: 141, train_loss 9.552131652832031, train_accuracy 0.5390625, val_loss 9.008498191833496, val_accuracy 0.5651999711990356\n",
      "Epoch: 142, train_loss 7.996079444885254, train_accuracy 0.61328125, val_loss 8.83940315246582, val_accuracy 0.5733333230018616\n",
      "Epoch: 143, train_loss 8.661678314208984, train_accuracy 0.58203125, val_loss 9.439013481140137, val_accuracy 0.5443999767303467\n",
      "Epoch: 144, train_loss 8.499776840209961, train_accuracy 0.58984375, val_loss 8.985672950744629, val_accuracy 0.566266655921936\n",
      "Epoch: 145, train_loss 8.985479354858398, train_accuracy 0.56640625, val_loss 9.13983154296875, val_accuracy 0.5587999820709229\n",
      "Epoch: 146, train_loss 9.147378921508789, train_accuracy 0.55859375, val_loss 9.035344123840332, val_accuracy 0.5640000104904175\n",
      "Epoch: 147, train_loss 9.390230178833008, train_accuracy 0.546875, val_loss 9.142735481262207, val_accuracy 0.5586666464805603\n",
      "Epoch: 148, train_loss 10.118782043457031, train_accuracy 0.51171875, val_loss 9.094005584716797, val_accuracy 0.5610666871070862\n",
      "Epoch: 149, train_loss 8.256926536560059, train_accuracy 0.6015625, val_loss 8.833462715148926, val_accuracy 0.5737333297729492\n",
      "Epoch: 150, train_loss 8.985479354858398, train_accuracy 0.56640625, val_loss 8.770380973815918, val_accuracy 0.5763999819755554\n",
      "Epoch: 151, train_loss 8.923942565917969, train_accuracy 0.56640625, val_loss 9.011260032653809, val_accuracy 0.5650666952133179\n",
      "Epoch: 152, train_loss 8.499776840209961, train_accuracy 0.58984375, val_loss 8.951834678649902, val_accuracy 0.5678666830062866\n",
      "Epoch: 153, train_loss 9.309280395507812, train_accuracy 0.55078125, val_loss 9.147317886352539, val_accuracy 0.5585333108901978\n",
      "Epoch: 154, train_loss 9.714031219482422, train_accuracy 0.53125, val_loss 8.786373138427734, val_accuracy 0.5757333040237427\n",
      "Epoch: 155, train_loss 8.580727577209473, train_accuracy 0.5859375, val_loss 8.838920593261719, val_accuracy 0.573199987411499\n",
      "Epoch: 156, train_loss 8.418827056884766, train_accuracy 0.59375, val_loss 8.797675132751465, val_accuracy 0.5754666924476624\n",
      "Epoch: 157, train_loss 8.823577880859375, train_accuracy 0.57421875, val_loss 8.840740203857422, val_accuracy 0.5733333230018616\n",
      "Epoch: 158, train_loss 9.066429138183594, train_accuracy 0.5625, val_loss 8.934442520141602, val_accuracy 0.5687999725341797\n",
      "Epoch: 159, train_loss 7.9331254959106445, train_accuracy 0.6171875, val_loss 8.702998161315918, val_accuracy 0.5797333121299744\n",
      "Epoch: 160, train_loss 9.228330612182617, train_accuracy 0.5546875, val_loss 8.761914253234863, val_accuracy 0.5769333243370056\n",
      "Epoch: 161, train_loss 9.066429138183594, train_accuracy 0.5625, val_loss 8.791470527648926, val_accuracy 0.5756000280380249\n",
      "Epoch: 162, train_loss 9.390230178833008, train_accuracy 0.546875, val_loss 8.914233207702637, val_accuracy 0.569599986076355\n",
      "Epoch: 163, train_loss 9.066429138183594, train_accuracy 0.5625, val_loss 8.949689865112305, val_accuracy 0.5681333541870117\n",
      "Epoch: 164, train_loss 7.690274715423584, train_accuracy 0.62890625, val_loss 8.80359172821045, val_accuracy 0.5750666856765747\n",
      "Epoch: 165, train_loss 9.147378921508789, train_accuracy 0.55859375, val_loss 8.974571228027344, val_accuracy 0.5669333338737488\n",
      "Epoch: 166, train_loss 7.528374195098877, train_accuracy 0.63671875, val_loss 8.975521087646484, val_accuracy 0.5667999982833862\n",
      "Epoch: 167, train_loss 9.390230178833008, train_accuracy 0.546875, val_loss 8.840609550476074, val_accuracy 0.5733333230018616\n",
      "Epoch: 168, train_loss 7.9331254959106445, train_accuracy 0.6171875, val_loss 8.638175010681152, val_accuracy 0.5830666422843933\n",
      "Epoch: 169, train_loss 8.985479354858398, train_accuracy 0.56640625, val_loss 8.769147872924805, val_accuracy 0.5766666531562805\n",
      "Epoch: 170, train_loss 9.390230178833008, train_accuracy 0.546875, val_loss 8.696465492248535, val_accuracy 0.5802666544914246\n",
      "Epoch: 171, train_loss 9.228328704833984, train_accuracy 0.5546875, val_loss 8.761666297912598, val_accuracy 0.5770666599273682\n",
      "Epoch: 172, train_loss 9.309280395507812, train_accuracy 0.55078125, val_loss 9.272756576538086, val_accuracy 0.5523999929428101\n",
      "Epoch: 173, train_loss 8.014076232910156, train_accuracy 0.61328125, val_loss 8.728031158447266, val_accuracy 0.5785333514213562\n",
      "Epoch: 174, train_loss 7.7712249755859375, train_accuracy 0.625, val_loss 8.632685661315918, val_accuracy 0.5833333134651184\n",
      "Epoch: 175, train_loss 9.2283296585083, train_accuracy 0.5546875, val_loss 8.77525520324707, val_accuracy 0.5763999819755554\n",
      "Epoch: 176, train_loss 7.852175235748291, train_accuracy 0.62109375, val_loss 8.744085311889648, val_accuracy 0.5777333378791809\n",
      "Epoch: 177, train_loss 8.175975799560547, train_accuracy 0.60546875, val_loss 8.687871932983398, val_accuracy 0.5806666612625122\n",
      "Epoch: 178, train_loss 9.147379875183105, train_accuracy 0.55859375, val_loss 8.783305168151855, val_accuracy 0.5761333107948303\n",
      "Epoch: 179, train_loss 8.823577880859375, train_accuracy 0.57421875, val_loss 9.054699897766113, val_accuracy 0.5630666613578796\n",
      "Epoch: 180, train_loss 9.147378921508789, train_accuracy 0.55859375, val_loss 8.84238338470459, val_accuracy 0.573199987411499\n",
      "Epoch: 181, train_loss 9.552130699157715, train_accuracy 0.5390625, val_loss 8.931755065917969, val_accuracy 0.5687999725341797\n",
      "Epoch: 182, train_loss 7.9331254959106445, train_accuracy 0.6171875, val_loss 8.694354057312012, val_accuracy 0.580133318901062\n",
      "Epoch: 183, train_loss 8.74262809753418, train_accuracy 0.578125, val_loss 8.754631042480469, val_accuracy 0.5773333311080933\n",
      "Epoch: 184, train_loss 9.066429138183594, train_accuracy 0.5625, val_loss 8.628191947937012, val_accuracy 0.5835999846458435\n",
      "Epoch: 185, train_loss 9.309280395507812, train_accuracy 0.55078125, val_loss 8.818024635314941, val_accuracy 0.574400007724762\n",
      "Epoch: 186, train_loss 9.633081436157227, train_accuracy 0.53515625, val_loss 8.751470565795898, val_accuracy 0.5774666666984558\n",
      "Epoch: 187, train_loss 10.037832260131836, train_accuracy 0.515625, val_loss 8.718116760253906, val_accuracy 0.579200029373169\n",
      "Epoch: 188, train_loss 9.066429138183594, train_accuracy 0.5625, val_loss 8.677349090576172, val_accuracy 0.5812000036239624\n",
      "Epoch: 189, train_loss 9.066429138183594, train_accuracy 0.5625, val_loss 8.675450325012207, val_accuracy 0.5812000036239624\n",
      "Epoch: 190, train_loss 8.580727577209473, train_accuracy 0.5859375, val_loss 8.75841999053955, val_accuracy 0.5773333311080933\n",
      "Epoch: 191, train_loss 7.528374195098877, train_accuracy 0.63671875, val_loss 8.733012199401855, val_accuracy 0.5784000158309937\n",
      "Epoch: 192, train_loss 9.633081436157227, train_accuracy 0.53515625, val_loss 8.813556671142578, val_accuracy 0.574400007724762\n",
      "Epoch: 193, train_loss 9.875931739807129, train_accuracy 0.5234375, val_loss 8.775612831115723, val_accuracy 0.576533317565918\n",
      "Epoch: 194, train_loss 8.580727577209473, train_accuracy 0.5859375, val_loss 8.68538761138916, val_accuracy 0.5806666612625122\n",
      "Epoch: 195, train_loss 9.147378921508789, train_accuracy 0.55859375, val_loss 8.637457847595215, val_accuracy 0.5831999778747559\n",
      "Epoch: 196, train_loss 8.175975799560547, train_accuracy 0.60546875, val_loss 8.617128372192383, val_accuracy 0.5839999914169312\n",
      "Epoch: 197, train_loss 7.9331254959106445, train_accuracy 0.6171875, val_loss 8.640259742736816, val_accuracy 0.5830666422843933\n",
      "Epoch: 198, train_loss 8.580727577209473, train_accuracy 0.5859375, val_loss 8.609678268432617, val_accuracy 0.5843999981880188\n",
      "Epoch: 199, train_loss 7.285523414611816, train_accuracy 0.6484375, val_loss 8.638692855834961, val_accuracy 0.5830666422843933\n",
      "Epoch: 200, train_loss 8.014076232910156, train_accuracy 0.61328125, val_loss 8.978804588317871, val_accuracy 0.5665333271026611\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, (batch_X, batch_Y) in enumerate(train_data.take(steps_per_epoch), 1):\n",
    "        run_optimizer(batch_X, batch_Y)\n",
    "\n",
    "    val_pred = model(valid_features)\n",
    "    val_loss = cross_entropy(val_pred, valid_labels)\n",
    "    val_acc = accuracy(val_pred, valid_labels)\n",
    "    train_pred = model(batch_X)\n",
    "    train_loss = cross_entropy(train_pred, batch_Y)\n",
    "    train_acc = accuracy(train_pred, batch_Y)\n",
    "    manager.save()\n",
    "\n",
    "    print(f\"Epoch: {epoch}, train_loss {train_loss}, train_accuracy {train_acc}, val_loss {val_loss}, val_accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89964352-f865-4417-afa5-26bfef13f437",
   "metadata": {
    "id": "89964352-f865-4417-afa5-26bfef13f437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss 8.052408218383789, Test_accuracy 0.6111999750137329\n"
     ]
    }
   ],
   "source": [
    "test_pred = model(test_features)\n",
    "test_loss = cross_entropy(test_pred, test_labels)\n",
    "test_acc = accuracy(test_pred, test_labels)\n",
    "print(f\"Test_loss {test_loss}, Test_accuracy {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa8601-7cee-442a-a667-c1e849ca20ce",
   "metadata": {
    "id": "cbaa8601-7cee-442a-a667-c1e849ca20ce"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
