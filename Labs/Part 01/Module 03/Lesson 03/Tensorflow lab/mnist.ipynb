{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6d08fe36-d4fa-4292-a54c-ccc02f156920",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d08fe36-d4fa-4292-a54c-ccc02f156920",
        "outputId": "537fa111-5fb1-41db-95e0-f7c95b0c794d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data and modules loaded.\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Load the modules\n",
        "import pickle\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reload the data\n",
        "pickle_file = 'notMNIST.pickle'\n",
        "with open(pickle_file, 'rb') as f:\n",
        "  pickle_data = pickle.load(f)\n",
        "  train_features = pickle_data['train_dataset']\n",
        "  train_labels = pickle_data['train_labels']\n",
        "  valid_features = pickle_data['valid_dataset']\n",
        "  valid_labels = pickle_data['valid_labels']\n",
        "  test_features = pickle_data['test_dataset']\n",
        "  test_labels = pickle_data['test_labels']\n",
        "  del pickle_data  # Free up memory\n",
        "\n",
        "\n",
        "print('Data and modules loaded.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e49cb51f-2576-43b1-a76a-fa642597976d",
      "metadata": {
        "id": "e49cb51f-2576-43b1-a76a-fa642597976d"
      },
      "outputs": [],
      "source": [
        "# Data has been normalized\n",
        "total_samples = len(train_features)\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.008\n",
        "num_output = 10\n",
        "epochs = 100\n",
        "batch_size = 256\n",
        "steps_per_epoch = int(np.ceil(total_samples / batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2dd74ff5-8247-4304-a21e-227e1dc40857",
      "metadata": {
        "id": "2dd74ff5-8247-4304-a21e-227e1dc40857"
      },
      "outputs": [],
      "source": [
        "# Cleaning Data\n",
        "#valid_labels, test_labels = np.array(valid_labels, np.int64), np.array(test_labels, np.int64)\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_features, train_labels))\n",
        "val_features, test_features = np.array(valid_features, np.float32), np.array(test_features, np.float32)\n",
        "\n",
        "# Data has been normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "52a9b1dc-03ab-4628-ac52-544a0540979a",
      "metadata": {
        "id": "52a9b1dc-03ab-4628-ac52-544a0540979a"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "aa753673-88d7-4601-9dff-f9ade3381a24",
      "metadata": {
        "id": "aa753673-88d7-4601-9dff-f9ade3381a24"
      },
      "outputs": [],
      "source": [
        "features = train_features.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bdc4dec7-5917-4ff5-941e-3d82566529ac",
      "metadata": {
        "id": "bdc4dec7-5917-4ff5-941e-3d82566529ac"
      },
      "outputs": [],
      "source": [
        "W = tf.Variable(tf.random.normal([features, num_output], name=\"weights\"))\n",
        "B = tf.Variable(tf.zeros([num_output], name=\"bias\"))\n",
        "\n",
        "optimizer = tf.optimizers.SGD(learning_rate)\n",
        "\n",
        "# Model\n",
        "def model(X):\n",
        "    return tf.nn.softmax(tf.add(tf.matmul(X, W), B))\n",
        "\n",
        "def cross_entropy(y_pred, y_true):\n",
        "    # It has been one-hot encoded before storing as pickle\n",
        "    #y_true = tf.one_hot(y_true, depth=num_output)\n",
        "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
        "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred), 1))\n",
        "\n",
        "def accuracy(y_pred, y_true):\n",
        "    if len(y_true.shape) > 1 and y_true.shape[1] > 1:\n",
        "        y_true = tf.argmax(y_true, axis=1)\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "def run_optimizer(X, Y):\n",
        "    with tf.GradientTape() as g:\n",
        "        logit = model(X)\n",
        "        loss = cross_entropy(logit, Y)\n",
        "\n",
        "    gradients = g.gradient(loss, [W, B])\n",
        "    optimizer.apply_gradients(zip(gradients, [W, B]))\n",
        "    return None\n",
        "\n",
        "def batch_data(X, Y, batch_size):\n",
        "    output_data = []\n",
        "    sample_size = len(X)\n",
        "    for step in range(0, sample_size, batch_size):\n",
        "        start = batch_size * step\n",
        "        end = batch_size + start\n",
        "        batch_X = X[start:end]\n",
        "        batch_Y = Y[start:end]\n",
        "        yield batch_X, batch_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "eed6bd8f-4bdc-4110-8cec-91ba172b3b55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eed6bd8f-4bdc-4110-8cec-91ba172b3b55",
        "outputId": "494b6747-7a65-4099-c2c9-926f3fd6872a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, train_loss 9.039234161376953, train_accuracy 0.18359375, val_loss 8.769306182861328, val_accuracy 0.23253333568572998\n",
            "Epoch: 2, train_loss 6.908698081970215, train_accuracy 0.3203125, val_loss 6.341052055358887, val_accuracy 0.3834666609764099\n",
            "Epoch: 3, train_loss 5.318723201751709, train_accuracy 0.4765625, val_loss 5.422524929046631, val_accuracy 0.47813332080841064\n",
            "Epoch: 4, train_loss 5.640497207641602, train_accuracy 0.46875, val_loss 4.951755046844482, val_accuracy 0.527999997138977\n",
            "Epoch: 5, train_loss 4.5839409828186035, train_accuracy 0.59375, val_loss 4.6686906814575195, val_accuracy 0.5651999711990356\n",
            "Epoch: 6, train_loss 4.251703262329102, train_accuracy 0.5859375, val_loss 4.480134963989258, val_accuracy 0.5894666910171509\n",
            "Epoch: 7, train_loss 4.863069534301758, train_accuracy 0.5625, val_loss 4.347428798675537, val_accuracy 0.6062666773796082\n",
            "Epoch: 8, train_loss 3.965963125228882, train_accuracy 0.6640625, val_loss 4.247061252593994, val_accuracy 0.6204000115394592\n",
            "Epoch: 9, train_loss 4.447937965393066, train_accuracy 0.61328125, val_loss 4.165986061096191, val_accuracy 0.6299999952316284\n",
            "Epoch: 10, train_loss 4.079427719116211, train_accuracy 0.640625, val_loss 4.100656986236572, val_accuracy 0.6381333470344543\n",
            "Epoch: 11, train_loss 3.9895355701446533, train_accuracy 0.640625, val_loss 4.042210102081299, val_accuracy 0.6458666920661926\n",
            "Epoch: 12, train_loss 4.502771854400635, train_accuracy 0.640625, val_loss 3.9889297485351562, val_accuracy 0.6546666622161865\n",
            "Epoch: 13, train_loss 4.357571601867676, train_accuracy 0.6171875, val_loss 3.92348313331604, val_accuracy 0.659600019454956\n",
            "Epoch: 14, train_loss 3.2288901805877686, train_accuracy 0.65234375, val_loss 2.9645495414733887, val_accuracy 0.6782666444778442\n",
            "Epoch: 15, train_loss 2.543830156326294, train_accuracy 0.66796875, val_loss 2.437194347381592, val_accuracy 0.7042666673660278\n",
            "Epoch: 16, train_loss 2.2257943153381348, train_accuracy 0.73828125, val_loss 2.365835189819336, val_accuracy 0.7107999920845032\n",
            "Epoch: 17, train_loss 2.110018253326416, train_accuracy 0.75390625, val_loss 2.3069820404052734, val_accuracy 0.7162666916847229\n",
            "Epoch: 18, train_loss 2.4503655433654785, train_accuracy 0.703125, val_loss 2.2581233978271484, val_accuracy 0.7215999960899353\n",
            "Epoch: 19, train_loss 1.791135311126709, train_accuracy 0.76953125, val_loss 2.2147374153137207, val_accuracy 0.7265333533287048\n",
            "Epoch: 20, train_loss 2.105340003967285, train_accuracy 0.7421875, val_loss 2.177337169647217, val_accuracy 0.7311999797821045\n",
            "Epoch: 21, train_loss 1.7698588371276855, train_accuracy 0.74609375, val_loss 2.1438560485839844, val_accuracy 0.7353333234786987\n",
            "Epoch: 22, train_loss 2.5605101585388184, train_accuracy 0.703125, val_loss 2.113433837890625, val_accuracy 0.7378666400909424\n",
            "Epoch: 23, train_loss 1.6230146884918213, train_accuracy 0.76171875, val_loss 2.08638072013855, val_accuracy 0.7396000027656555\n",
            "Epoch: 24, train_loss 2.2764732837677, train_accuracy 0.6953125, val_loss 2.060945510864258, val_accuracy 0.7421333193778992\n",
            "Epoch: 25, train_loss 2.1490249633789062, train_accuracy 0.71484375, val_loss 2.0374550819396973, val_accuracy 0.7433333396911621\n",
            "Epoch: 26, train_loss 3.018744707107544, train_accuracy 0.65625, val_loss 2.014862298965454, val_accuracy 0.7444000244140625\n",
            "Epoch: 27, train_loss 2.3296875953674316, train_accuracy 0.71875, val_loss 1.9937020540237427, val_accuracy 0.7458666563034058\n",
            "Epoch: 28, train_loss 1.4660512208938599, train_accuracy 0.78515625, val_loss 1.9744354486465454, val_accuracy 0.7472000122070312\n",
            "Epoch: 29, train_loss 1.9076130390167236, train_accuracy 0.765625, val_loss 1.9559125900268555, val_accuracy 0.7486666440963745\n",
            "Epoch: 30, train_loss 1.770156741142273, train_accuracy 0.73828125, val_loss 1.9388134479522705, val_accuracy 0.7508000135421753\n",
            "Epoch: 31, train_loss 1.7199578285217285, train_accuracy 0.76171875, val_loss 1.9212274551391602, val_accuracy 0.7526666522026062\n",
            "Epoch: 32, train_loss 2.2101120948791504, train_accuracy 0.734375, val_loss 1.905737280845642, val_accuracy 0.753600001335144\n",
            "Epoch: 33, train_loss 2.0168402194976807, train_accuracy 0.74609375, val_loss 1.889878511428833, val_accuracy 0.7546666860580444\n",
            "Epoch: 34, train_loss 1.8500895500183105, train_accuracy 0.7421875, val_loss 1.8753440380096436, val_accuracy 0.7561333179473877\n",
            "Epoch: 35, train_loss 1.5248498916625977, train_accuracy 0.76953125, val_loss 1.8607946634292603, val_accuracy 0.7576000094413757\n",
            "Epoch: 36, train_loss 1.8453369140625, train_accuracy 0.76953125, val_loss 1.8459933996200562, val_accuracy 0.7580000162124634\n",
            "Epoch: 37, train_loss 1.5724626779556274, train_accuracy 0.80078125, val_loss 1.832687497138977, val_accuracy 0.7594666481018066\n",
            "Epoch: 38, train_loss 1.3988757133483887, train_accuracy 0.78515625, val_loss 1.819535493850708, val_accuracy 0.7603999972343445\n",
            "Epoch: 39, train_loss 2.4822216033935547, train_accuracy 0.72265625, val_loss 1.8065780401229858, val_accuracy 0.7608000040054321\n",
            "Epoch: 40, train_loss 1.9105364084243774, train_accuracy 0.77734375, val_loss 1.7934118509292603, val_accuracy 0.7606666684150696\n",
            "Epoch: 41, train_loss 1.6915968656539917, train_accuracy 0.77734375, val_loss 1.7817738056182861, val_accuracy 0.7621333599090576\n",
            "Epoch: 42, train_loss 1.7179787158966064, train_accuracy 0.7734375, val_loss 1.7697184085845947, val_accuracy 0.7625333070755005\n",
            "Epoch: 43, train_loss 1.8582708835601807, train_accuracy 0.7421875, val_loss 1.7580363750457764, val_accuracy 0.7625333070755005\n",
            "Epoch: 44, train_loss 1.827933430671692, train_accuracy 0.73828125, val_loss 1.7472145557403564, val_accuracy 0.7630666494369507\n",
            "Epoch: 45, train_loss 2.0017476081848145, train_accuracy 0.74609375, val_loss 1.735759973526001, val_accuracy 0.7654666900634766\n",
            "Epoch: 46, train_loss 1.538245439529419, train_accuracy 0.76953125, val_loss 1.7263373136520386, val_accuracy 0.7652000188827515\n",
            "Epoch: 47, train_loss 1.5630271434783936, train_accuracy 0.7734375, val_loss 1.7147448062896729, val_accuracy 0.7662666440010071\n",
            "Epoch: 48, train_loss 1.6494817733764648, train_accuracy 0.78125, val_loss 1.704972505569458, val_accuracy 0.7665333151817322\n",
            "Epoch: 49, train_loss 1.353084921836853, train_accuracy 0.77734375, val_loss 1.6952887773513794, val_accuracy 0.7665333151817322\n",
            "Epoch: 50, train_loss 1.7553074359893799, train_accuracy 0.73828125, val_loss 1.6862329244613647, val_accuracy 0.7666666507720947\n",
            "Epoch: 51, train_loss 2.4502081871032715, train_accuracy 0.70703125, val_loss 1.6770076751708984, val_accuracy 0.7669333219528198\n",
            "Epoch: 52, train_loss 1.842180609703064, train_accuracy 0.7578125, val_loss 1.6666134595870972, val_accuracy 0.7675999999046326\n",
            "Epoch: 53, train_loss 1.1854745149612427, train_accuracy 0.8046875, val_loss 1.658393144607544, val_accuracy 0.7681333422660828\n",
            "Epoch: 54, train_loss 1.831648588180542, train_accuracy 0.76171875, val_loss 1.649932622909546, val_accuracy 0.7680000066757202\n",
            "Epoch: 55, train_loss 1.8382530212402344, train_accuracy 0.7578125, val_loss 1.641298532485962, val_accuracy 0.7678666710853577\n",
            "Epoch: 56, train_loss 1.7180731296539307, train_accuracy 0.71875, val_loss 1.6323988437652588, val_accuracy 0.7689333558082581\n",
            "Epoch: 57, train_loss 1.750303030014038, train_accuracy 0.78515625, val_loss 1.6241058111190796, val_accuracy 0.768666684627533\n",
            "Epoch: 58, train_loss 1.3500819206237793, train_accuracy 0.7890625, val_loss 1.6160264015197754, val_accuracy 0.7692000269889832\n",
            "Epoch: 59, train_loss 1.9209628105163574, train_accuracy 0.73046875, val_loss 1.6083844900131226, val_accuracy 0.7697333097457886\n",
            "Epoch: 60, train_loss 1.7060768604278564, train_accuracy 0.7578125, val_loss 1.6007217168807983, val_accuracy 0.7694666385650635\n",
            "Epoch: 61, train_loss 1.4273746013641357, train_accuracy 0.7578125, val_loss 1.593158483505249, val_accuracy 0.769599974155426\n",
            "Epoch: 62, train_loss 2.0057592391967773, train_accuracy 0.73828125, val_loss 1.585946798324585, val_accuracy 0.7698666453361511\n",
            "Epoch: 63, train_loss 1.6854476928710938, train_accuracy 0.76953125, val_loss 1.578299880027771, val_accuracy 0.7703999876976013\n",
            "Epoch: 64, train_loss 1.1997284889221191, train_accuracy 0.7734375, val_loss 1.5716710090637207, val_accuracy 0.7701333165168762\n",
            "Epoch: 65, train_loss 1.9284029006958008, train_accuracy 0.73828125, val_loss 1.5641944408416748, val_accuracy 0.7705333232879639\n",
            "Epoch: 66, train_loss 1.568547248840332, train_accuracy 0.796875, val_loss 1.557443618774414, val_accuracy 0.770799994468689\n",
            "Epoch: 67, train_loss 1.2734538316726685, train_accuracy 0.77734375, val_loss 1.5504858493804932, val_accuracy 0.770799994468689\n",
            "Epoch: 68, train_loss 1.8372490406036377, train_accuracy 0.70703125, val_loss 1.5446456670761108, val_accuracy 0.7706666588783264\n",
            "Epoch: 69, train_loss 1.8097758293151855, train_accuracy 0.765625, val_loss 1.5375807285308838, val_accuracy 0.7710666656494141\n",
            "Epoch: 70, train_loss 1.5774158239364624, train_accuracy 0.76171875, val_loss 1.5314393043518066, val_accuracy 0.770799994468689\n",
            "Epoch: 71, train_loss 2.0119969844818115, train_accuracy 0.734375, val_loss 1.525383472442627, val_accuracy 0.770799994468689\n",
            "Epoch: 72, train_loss 1.3286465406417847, train_accuracy 0.7734375, val_loss 1.5190463066101074, val_accuracy 0.7714666724205017\n",
            "Epoch: 73, train_loss 1.979750156402588, train_accuracy 0.72265625, val_loss 1.5126821994781494, val_accuracy 0.7714666724205017\n",
            "Epoch: 74, train_loss 1.3091609477996826, train_accuracy 0.7578125, val_loss 1.5069036483764648, val_accuracy 0.7713333368301392\n",
            "Epoch: 75, train_loss 1.3476674556732178, train_accuracy 0.7890625, val_loss 1.5009586811065674, val_accuracy 0.7717333436012268\n",
            "Epoch: 76, train_loss 1.7065765857696533, train_accuracy 0.76953125, val_loss 1.4950039386749268, val_accuracy 0.7720000147819519\n",
            "Epoch: 77, train_loss 1.598026990890503, train_accuracy 0.78515625, val_loss 1.4894657135009766, val_accuracy 0.7721333503723145\n",
            "Epoch: 78, train_loss 1.2517540454864502, train_accuracy 0.7734375, val_loss 1.4834144115447998, val_accuracy 0.772933304309845\n",
            "Epoch: 79, train_loss 1.3065747022628784, train_accuracy 0.80078125, val_loss 1.4774158000946045, val_accuracy 0.7717333436012268\n",
            "Epoch: 80, train_loss 1.6475613117218018, train_accuracy 0.75, val_loss 1.472241997718811, val_accuracy 0.7724000215530396\n",
            "Epoch: 81, train_loss 1.6191027164459229, train_accuracy 0.73046875, val_loss 1.466747522354126, val_accuracy 0.772266685962677\n",
            "Epoch: 82, train_loss 1.224261999130249, train_accuracy 0.7890625, val_loss 1.4619427919387817, val_accuracy 0.7726666927337646\n",
            "Epoch: 83, train_loss 1.6584880352020264, train_accuracy 0.7734375, val_loss 1.4556752443313599, val_accuracy 0.7730666399002075\n",
            "Epoch: 84, train_loss 1.6268987655639648, train_accuracy 0.76171875, val_loss 1.4507174491882324, val_accuracy 0.7735999822616577\n",
            "Epoch: 85, train_loss 1.2213225364685059, train_accuracy 0.79296875, val_loss 1.4456439018249512, val_accuracy 0.7737333178520203\n",
            "Epoch: 86, train_loss 1.4112756252288818, train_accuracy 0.78515625, val_loss 1.4405156373977661, val_accuracy 0.7734666466712952\n",
            "Epoch: 87, train_loss 1.5171921253204346, train_accuracy 0.796875, val_loss 1.435218095779419, val_accuracy 0.7734666466712952\n",
            "Epoch: 88, train_loss 1.124666690826416, train_accuracy 0.80078125, val_loss 1.430214524269104, val_accuracy 0.7742666602134705\n",
            "Epoch: 89, train_loss 1.1679980754852295, train_accuracy 0.76953125, val_loss 1.4250472784042358, val_accuracy 0.7741333246231079\n",
            "Epoch: 90, train_loss 1.331129550933838, train_accuracy 0.76171875, val_loss 1.4201266765594482, val_accuracy 0.7734666466712952\n",
            "Epoch: 91, train_loss 1.2338342666625977, train_accuracy 0.77734375, val_loss 1.4155592918395996, val_accuracy 0.7733333110809326\n",
            "Epoch: 92, train_loss 1.6516958475112915, train_accuracy 0.7578125, val_loss 1.4109488725662231, val_accuracy 0.7737333178520203\n",
            "Epoch: 93, train_loss 1.4627685546875, train_accuracy 0.75390625, val_loss 1.4068571329116821, val_accuracy 0.7745333313941956\n",
            "Epoch: 94, train_loss 1.5580062866210938, train_accuracy 0.76953125, val_loss 1.402053952217102, val_accuracy 0.7741333246231079\n",
            "Epoch: 95, train_loss 1.7190186977386475, train_accuracy 0.75, val_loss 1.3971383571624756, val_accuracy 0.7738666534423828\n",
            "Epoch: 96, train_loss 1.3651069402694702, train_accuracy 0.78515625, val_loss 1.3927741050720215, val_accuracy 0.7737333178520203\n",
            "Epoch: 97, train_loss 1.2171119451522827, train_accuracy 0.796875, val_loss 1.388040542602539, val_accuracy 0.7741333246231079\n",
            "Epoch: 98, train_loss 1.619706392288208, train_accuracy 0.70703125, val_loss 1.3845199346542358, val_accuracy 0.774399995803833\n",
            "Epoch: 99, train_loss 1.6000807285308838, train_accuracy 0.7265625, val_loss 1.3798205852508545, val_accuracy 0.7745333313941956\n",
            "Epoch: 100, train_loss 1.0813496112823486, train_accuracy 0.7734375, val_loss 1.37559175491333, val_accuracy 0.774399995803833\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "for epoch in range(1, epochs + 1):\n",
        "    for step, (batch_X, batch_Y) in enumerate(train_data.take(steps_per_epoch), 1):\n",
        "        run_optimizer(batch_X, batch_Y)\n",
        "\n",
        "    val_pred = model(valid_features)\n",
        "    val_loss = cross_entropy(val_pred, valid_labels)\n",
        "    val_acc = accuracy(val_pred, valid_labels)\n",
        "    train_pred = model(batch_X)\n",
        "    train_loss = cross_entropy(train_pred, batch_Y)\n",
        "    train_acc = accuracy(train_pred, batch_Y)\n",
        "    print(f\"Epoch: {epoch}, train_loss {train_loss}, train_accuracy {train_acc}, val_loss {val_loss}, val_accuracy {val_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "89964352-f865-4417-afa5-26bfef13f437",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89964352-f865-4417-afa5-26bfef13f437",
        "outputId": "4bb4f448-fe33-4321-84b1-8d4c7b7c1281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test_loss 0.8740248084068298, Test_accuracy 0.8393999934196472\n"
          ]
        }
      ],
      "source": [
        "test_pred = model(test_features)\n",
        "test_loss = cross_entropy(test_pred, test_labels)\n",
        "test_acc = accuracy(test_pred, test_labels)\n",
        "print(f\"Test_loss {test_loss}, Test_accuracy {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbaa8601-7cee-442a-a667-c1e849ca20ce",
      "metadata": {
        "id": "cbaa8601-7cee-442a-a667-c1e849ca20ce"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}