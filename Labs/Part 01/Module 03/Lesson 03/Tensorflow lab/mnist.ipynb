{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6d08fe36-d4fa-4292-a54c-ccc02f156920",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d08fe36-d4fa-4292-a54c-ccc02f156920",
        "outputId": "5b736ee4-d849-4128-bdf5-b65022adee2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data and modules loaded.\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Load the modules\n",
        "import pickle\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reload the data\n",
        "pickle_file = 'notMNIST.pickle'\n",
        "with open(pickle_file, 'rb') as f:\n",
        "  pickle_data = pickle.load(f)\n",
        "  train_features = pickle_data['train_dataset']\n",
        "  train_labels = pickle_data['train_labels']\n",
        "  valid_features = pickle_data['valid_dataset']\n",
        "  valid_labels = pickle_data['valid_labels']\n",
        "  test_features = pickle_data['test_dataset']\n",
        "  test_labels = pickle_data['test_labels']\n",
        "  del pickle_data  # Free up memory\n",
        "\n",
        "\n",
        "print('Data and modules loaded.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e49cb51f-2576-43b1-a76a-fa642597976d",
      "metadata": {
        "id": "e49cb51f-2576-43b1-a76a-fa642597976d"
      },
      "outputs": [],
      "source": [
        "# Data has been normalized\n",
        "total_samples = len(train_features)\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.008\n",
        "num_output = 10\n",
        "epochs = 100\n",
        "batch_size = 500\n",
        "steps_per_epoch = int(np.ceil(total_samples / batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2dd74ff5-8247-4304-a21e-227e1dc40857",
      "metadata": {
        "id": "2dd74ff5-8247-4304-a21e-227e1dc40857"
      },
      "outputs": [],
      "source": [
        "# Cleaning Data\n",
        "#valid_labels, test_labels = np.array(valid_labels, np.int64), np.array(test_labels, np.int64)\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_features, train_labels))\n",
        "val_features, test_features = np.array(valid_features, np.float32), np.array(test_features, np.float32)\n",
        "\n",
        "# Data has been normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "52a9b1dc-03ab-4628-ac52-544a0540979a",
      "metadata": {
        "id": "52a9b1dc-03ab-4628-ac52-544a0540979a"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "aa753673-88d7-4601-9dff-f9ade3381a24",
      "metadata": {
        "id": "aa753673-88d7-4601-9dff-f9ade3381a24"
      },
      "outputs": [],
      "source": [
        "features = train_features.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bdc4dec7-5917-4ff5-941e-3d82566529ac",
      "metadata": {
        "id": "bdc4dec7-5917-4ff5-941e-3d82566529ac"
      },
      "outputs": [],
      "source": [
        "W = tf.Variable(tf.random.normal([features, num_output], name=\"weights\"))\n",
        "B = tf.Variable(tf.random.normal([num_output], name=\"bias\"))\n",
        "\n",
        "optimizer = tf.optimizers.SGD(learning_rate)\n",
        "\n",
        "# Model\n",
        "def model(X):\n",
        "    return tf.nn.softmax(tf.add(tf.matmul(X, W), B))\n",
        "\n",
        "def cross_entropy(y_pred, y_true):\n",
        "    # It has been one-hot encoded before storing as pickle\n",
        "    #y_true = tf.one_hot(y_true, depth=num_output)\n",
        "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
        "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred), 1))\n",
        "\n",
        "def accuracy(y_pred, y_true):\n",
        "    if len(y_true.shape) > 1 and y_true.shape[1] > 1:\n",
        "        y_true = tf.argmax(y_true, axis=1)\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "def run_optimizer(X, Y):\n",
        "    with tf.GradientTape() as g:\n",
        "        logit = model(X)\n",
        "        loss = cross_entropy(logit, Y)\n",
        "\n",
        "    gradients = g.gradient(loss, [W, B])\n",
        "    optimizer.apply_gradients(zip(gradients, [W, B]))\n",
        "    return None\n",
        "\n",
        "def batch_data(X, Y, batch_size):\n",
        "    output_data = []\n",
        "    sample_size = len(X)\n",
        "    for step in range(0, sample_size, batch_size):\n",
        "        start = batch_size * step\n",
        "        end = batch_size + start\n",
        "        batch_X = X[start:end]\n",
        "        batch_Y = Y[start:end]\n",
        "        yield batch_X, batch_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "eed6bd8f-4bdc-4110-8cec-91ba172b3b55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eed6bd8f-4bdc-4110-8cec-91ba172b3b55",
        "outputId": "07cca147-f075-4aa0-afc2-78d8bc915bb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, train_loss 14.702600479125977, train_accuracy 0.1340000033378601, val_loss 15.237394332885742, val_accuracy 0.1146666631102562\n",
            "Epoch: 2, train_loss 12.004823684692383, train_accuracy 0.15000000596046448, val_loss 12.189475059509277, val_accuracy 0.14813333749771118\n",
            "Epoch: 3, train_loss 9.592134475708008, train_accuracy 0.23600000143051147, val_loss 9.940840721130371, val_accuracy 0.22759999334812164\n",
            "Epoch: 4, train_loss 8.113605499267578, train_accuracy 0.3540000021457672, val_loss 8.66319751739502, val_accuracy 0.3160000145435333\n",
            "Epoch: 5, train_loss 7.525343418121338, train_accuracy 0.38600000739097595, val_loss 7.873009204864502, val_accuracy 0.3761333227157593\n",
            "Epoch: 6, train_loss 7.5171918869018555, train_accuracy 0.3659999966621399, val_loss 7.268082618713379, val_accuracy 0.41413334012031555\n",
            "Epoch: 7, train_loss 6.729814052581787, train_accuracy 0.4099999964237213, val_loss 6.795907497406006, val_accuracy 0.44306665658950806\n",
            "Epoch: 8, train_loss 6.190457820892334, train_accuracy 0.45399999618530273, val_loss 6.355926990509033, val_accuracy 0.45559999346733093\n",
            "Epoch: 9, train_loss 5.736882209777832, train_accuracy 0.49000000953674316, val_loss 5.875168800354004, val_accuracy 0.4787999987602234\n",
            "Epoch: 10, train_loss 5.534085273742676, train_accuracy 0.5180000066757202, val_loss 5.439250946044922, val_accuracy 0.5106666684150696\n",
            "Epoch: 11, train_loss 4.598702430725098, train_accuracy 0.5640000104904175, val_loss 5.141432285308838, val_accuracy 0.5314666628837585\n",
            "Epoch: 12, train_loss 5.165520191192627, train_accuracy 0.5299999713897705, val_loss 4.942626953125, val_accuracy 0.5540000200271606\n",
            "Epoch: 13, train_loss 4.777174949645996, train_accuracy 0.5680000185966492, val_loss 4.799810409545898, val_accuracy 0.5698666572570801\n",
            "Epoch: 14, train_loss 4.352241516113281, train_accuracy 0.578000009059906, val_loss 4.691943168640137, val_accuracy 0.5830666422843933\n",
            "Epoch: 15, train_loss 4.79224157333374, train_accuracy 0.6119999885559082, val_loss 4.606193542480469, val_accuracy 0.5942666530609131\n",
            "Epoch: 16, train_loss 4.371757507324219, train_accuracy 0.6359999775886536, val_loss 4.535207748413086, val_accuracy 0.6047999858856201\n",
            "Epoch: 17, train_loss 4.161507606506348, train_accuracy 0.6100000143051147, val_loss 4.47481107711792, val_accuracy 0.6137333512306213\n",
            "Epoch: 18, train_loss 4.523673057556152, train_accuracy 0.5960000157356262, val_loss 4.423132419586182, val_accuracy 0.6191999912261963\n",
            "Epoch: 19, train_loss 4.350662708282471, train_accuracy 0.5879999995231628, val_loss 4.377380847930908, val_accuracy 0.6241333484649658\n",
            "Epoch: 20, train_loss 4.108631134033203, train_accuracy 0.656000018119812, val_loss 4.3365068435668945, val_accuracy 0.6304000020027161\n",
            "Epoch: 21, train_loss 4.5540852546691895, train_accuracy 0.628000020980835, val_loss 4.299527645111084, val_accuracy 0.634933352470398\n",
            "Epoch: 22, train_loss 4.212225914001465, train_accuracy 0.6200000047683716, val_loss 4.2656965255737305, val_accuracy 0.6397333145141602\n",
            "Epoch: 23, train_loss 4.040677070617676, train_accuracy 0.6600000262260437, val_loss 4.233577728271484, val_accuracy 0.644266664981842\n",
            "Epoch: 24, train_loss 3.8487865924835205, train_accuracy 0.6600000262260437, val_loss 4.199914455413818, val_accuracy 0.647599995136261\n",
            "Epoch: 25, train_loss 3.9308817386627197, train_accuracy 0.6399999856948853, val_loss 4.162720680236816, val_accuracy 0.651199996471405\n",
            "Epoch: 26, train_loss 3.7885327339172363, train_accuracy 0.6899999976158142, val_loss 4.108680248260498, val_accuracy 0.653333306312561\n",
            "Epoch: 27, train_loss 3.707369565963745, train_accuracy 0.6639999747276306, val_loss 4.016336917877197, val_accuracy 0.6557333469390869\n",
            "Epoch: 28, train_loss 3.7087676525115967, train_accuracy 0.671999990940094, val_loss 3.790445566177368, val_accuracy 0.6566666960716248\n",
            "Epoch: 29, train_loss 3.076934337615967, train_accuracy 0.6779999732971191, val_loss 3.2164175510406494, val_accuracy 0.6514666676521301\n",
            "Epoch: 30, train_loss 2.7325501441955566, train_accuracy 0.671999990940094, val_loss 2.914201021194458, val_accuracy 0.6553333401679993\n",
            "Epoch: 31, train_loss 2.3254554271698, train_accuracy 0.6880000233650208, val_loss 2.7029476165771484, val_accuracy 0.6687999963760376\n",
            "Epoch: 32, train_loss 2.754685401916504, train_accuracy 0.6539999842643738, val_loss 2.571585178375244, val_accuracy 0.6796000003814697\n",
            "Epoch: 33, train_loss 2.2449758052825928, train_accuracy 0.6899999976158142, val_loss 2.4890570640563965, val_accuracy 0.6886666417121887\n",
            "Epoch: 34, train_loss 2.451551914215088, train_accuracy 0.6819999814033508, val_loss 2.4316091537475586, val_accuracy 0.6949333548545837\n",
            "Epoch: 35, train_loss 2.9083938598632812, train_accuracy 0.6819999814033508, val_loss 2.3878402709960938, val_accuracy 0.7021333575248718\n",
            "Epoch: 36, train_loss 2.430997610092163, train_accuracy 0.6919999718666077, val_loss 2.352057695388794, val_accuracy 0.7082666754722595\n",
            "Epoch: 37, train_loss 2.390174150466919, train_accuracy 0.722000002861023, val_loss 2.322333335876465, val_accuracy 0.712933361530304\n",
            "Epoch: 38, train_loss 2.152338981628418, train_accuracy 0.7120000123977661, val_loss 2.296272039413452, val_accuracy 0.7164000272750854\n",
            "Epoch: 39, train_loss 2.6159868240356445, train_accuracy 0.6639999747276306, val_loss 2.2731480598449707, val_accuracy 0.7189333438873291\n",
            "Epoch: 40, train_loss 2.0620434284210205, train_accuracy 0.7480000257492065, val_loss 2.252354383468628, val_accuracy 0.7217333316802979\n",
            "Epoch: 41, train_loss 2.1597046852111816, train_accuracy 0.7379999756813049, val_loss 2.2336206436157227, val_accuracy 0.724133312702179\n",
            "Epoch: 42, train_loss 2.0095393657684326, train_accuracy 0.7260000109672546, val_loss 2.2156178951263428, val_accuracy 0.7266666889190674\n",
            "Epoch: 43, train_loss 1.875328779220581, train_accuracy 0.7639999985694885, val_loss 2.1994423866271973, val_accuracy 0.7286666631698608\n",
            "Epoch: 44, train_loss 2.7552645206451416, train_accuracy 0.7020000219345093, val_loss 2.1836767196655273, val_accuracy 0.7315999865531921\n",
            "Epoch: 45, train_loss 2.0286433696746826, train_accuracy 0.7419999837875366, val_loss 2.1690738201141357, val_accuracy 0.7332000136375427\n",
            "Epoch: 46, train_loss 2.213897466659546, train_accuracy 0.722000002861023, val_loss 2.1546900272369385, val_accuracy 0.7351999878883362\n",
            "Epoch: 47, train_loss 2.5533359050750732, train_accuracy 0.7379999756813049, val_loss 2.141178846359253, val_accuracy 0.7366666793823242\n",
            "Epoch: 48, train_loss 1.4896271228790283, train_accuracy 0.7519999742507935, val_loss 2.1277310848236084, val_accuracy 0.7377333045005798\n",
            "Epoch: 49, train_loss 1.951765775680542, train_accuracy 0.7540000081062317, val_loss 2.115299701690674, val_accuracy 0.7396000027656555\n",
            "Epoch: 50, train_loss 2.3358283042907715, train_accuracy 0.7260000109672546, val_loss 2.1034910678863525, val_accuracy 0.7406666874885559\n",
            "Epoch: 51, train_loss 1.9498376846313477, train_accuracy 0.7739999890327454, val_loss 2.0916080474853516, val_accuracy 0.7423999905586243\n",
            "Epoch: 52, train_loss 1.699496865272522, train_accuracy 0.765999972820282, val_loss 2.080333709716797, val_accuracy 0.7429333329200745\n",
            "Epoch: 53, train_loss 1.8856651782989502, train_accuracy 0.734000027179718, val_loss 2.0698204040527344, val_accuracy 0.7436000108718872\n",
            "Epoch: 54, train_loss 2.3339462280273438, train_accuracy 0.722000002861023, val_loss 2.0589332580566406, val_accuracy 0.7449333071708679\n",
            "Epoch: 55, train_loss 2.128422498703003, train_accuracy 0.7260000109672546, val_loss 2.0488531589508057, val_accuracy 0.7447999715805054\n",
            "Epoch: 56, train_loss 2.0391414165496826, train_accuracy 0.7540000081062317, val_loss 2.0385971069335938, val_accuracy 0.7454666495323181\n",
            "Epoch: 57, train_loss 2.0724258422851562, train_accuracy 0.7620000243186951, val_loss 2.0288708209991455, val_accuracy 0.746399998664856\n",
            "Epoch: 58, train_loss 2.349550247192383, train_accuracy 0.7360000014305115, val_loss 2.0194077491760254, val_accuracy 0.7473333477973938\n",
            "Epoch: 59, train_loss 2.009857416152954, train_accuracy 0.7400000095367432, val_loss 2.009995222091675, val_accuracy 0.747866690158844\n",
            "Epoch: 60, train_loss 1.9865972995758057, train_accuracy 0.7720000147819519, val_loss 2.001157760620117, val_accuracy 0.748533308506012\n",
            "Epoch: 61, train_loss 2.262836456298828, train_accuracy 0.7379999756813049, val_loss 1.9925694465637207, val_accuracy 0.7486666440963745\n",
            "Epoch: 62, train_loss 2.4221763610839844, train_accuracy 0.7319999933242798, val_loss 1.9839762449264526, val_accuracy 0.7495999932289124\n",
            "Epoch: 63, train_loss 1.939629316329956, train_accuracy 0.765999972820282, val_loss 1.9756898880004883, val_accuracy 0.7497333288192749\n",
            "Epoch: 64, train_loss 2.1318349838256836, train_accuracy 0.7400000095367432, val_loss 1.967362880706787, val_accuracy 0.7501333355903625\n",
            "Epoch: 65, train_loss 1.9507901668548584, train_accuracy 0.7300000190734863, val_loss 1.9594672918319702, val_accuracy 0.7506666779518127\n",
            "Epoch: 66, train_loss 2.0276119709014893, train_accuracy 0.7279999852180481, val_loss 1.9513086080551147, val_accuracy 0.7510666847229004\n",
            "Epoch: 67, train_loss 1.649288296699524, train_accuracy 0.7760000228881836, val_loss 1.94400155544281, val_accuracy 0.751466691493988\n",
            "Epoch: 68, train_loss 1.882607102394104, train_accuracy 0.75, val_loss 1.9367305040359497, val_accuracy 0.7526666522026062\n",
            "Epoch: 69, train_loss 1.8635146617889404, train_accuracy 0.734000027179718, val_loss 1.9288105964660645, val_accuracy 0.7534666657447815\n",
            "Epoch: 70, train_loss 1.9066455364227295, train_accuracy 0.7360000014305115, val_loss 1.9218425750732422, val_accuracy 0.7542666792869568\n",
            "Epoch: 71, train_loss 1.7552345991134644, train_accuracy 0.7519999742507935, val_loss 1.9148056507110596, val_accuracy 0.7545333504676819\n",
            "Epoch: 72, train_loss 2.1941888332366943, train_accuracy 0.7300000190734863, val_loss 1.9079599380493164, val_accuracy 0.7550666928291321\n",
            "Epoch: 73, train_loss 1.8332340717315674, train_accuracy 0.7599999904632568, val_loss 1.901098608970642, val_accuracy 0.755466639995575\n",
            "Epoch: 74, train_loss 1.9947549104690552, train_accuracy 0.7459999918937683, val_loss 1.8942617177963257, val_accuracy 0.7557333111763\n",
            "Epoch: 75, train_loss 2.0314126014709473, train_accuracy 0.734000027179718, val_loss 1.8877742290496826, val_accuracy 0.7561333179473877\n",
            "Epoch: 76, train_loss 2.2907776832580566, train_accuracy 0.7200000286102295, val_loss 1.881361722946167, val_accuracy 0.7574666738510132\n",
            "Epoch: 77, train_loss 2.118588447570801, train_accuracy 0.7300000190734863, val_loss 1.8752468824386597, val_accuracy 0.7580000162124634\n",
            "Epoch: 78, train_loss 2.0247552394866943, train_accuracy 0.75, val_loss 1.868860125541687, val_accuracy 0.7591999769210815\n",
            "Epoch: 79, train_loss 1.6567137241363525, train_accuracy 0.7620000243186951, val_loss 1.8627878427505493, val_accuracy 0.7602666616439819\n",
            "Epoch: 80, train_loss 1.8629183769226074, train_accuracy 0.7440000176429749, val_loss 1.856734037399292, val_accuracy 0.7603999972343445\n",
            "Epoch: 81, train_loss 1.806066870689392, train_accuracy 0.7799999713897705, val_loss 1.8503981828689575, val_accuracy 0.7601333260536194\n",
            "Epoch: 82, train_loss 1.9724310636520386, train_accuracy 0.7459999918937683, val_loss 1.844734787940979, val_accuracy 0.7608000040054321\n",
            "Epoch: 83, train_loss 2.055114984512329, train_accuracy 0.7540000081062317, val_loss 1.838857650756836, val_accuracy 0.7609333395957947\n",
            "Epoch: 84, train_loss 2.011050224304199, train_accuracy 0.7400000095367432, val_loss 1.8334099054336548, val_accuracy 0.760533332824707\n",
            "Epoch: 85, train_loss 2.032329559326172, train_accuracy 0.7279999852180481, val_loss 1.8273329734802246, val_accuracy 0.7614666819572449\n",
            "Epoch: 86, train_loss 2.0182487964630127, train_accuracy 0.7279999852180481, val_loss 1.8220529556274414, val_accuracy 0.7618666887283325\n",
            "Epoch: 87, train_loss 1.546425700187683, train_accuracy 0.777999997138977, val_loss 1.8165366649627686, val_accuracy 0.7621333599090576\n",
            "Epoch: 88, train_loss 1.547898530960083, train_accuracy 0.7799999713897705, val_loss 1.8110915422439575, val_accuracy 0.7623999714851379\n",
            "Epoch: 89, train_loss 1.894841194152832, train_accuracy 0.7419999837875366, val_loss 1.8057103157043457, val_accuracy 0.7625333070755005\n",
            "Epoch: 90, train_loss 1.7470320463180542, train_accuracy 0.7459999918937683, val_loss 1.8000930547714233, val_accuracy 0.762666642665863\n",
            "Epoch: 91, train_loss 1.8194795846939087, train_accuracy 0.7419999837875366, val_loss 1.7950273752212524, val_accuracy 0.7625333070755005\n",
            "Epoch: 92, train_loss 2.088308572769165, train_accuracy 0.734000027179718, val_loss 1.7900842428207397, val_accuracy 0.7623999714851379\n",
            "Epoch: 93, train_loss 1.9413524866104126, train_accuracy 0.7639999985694885, val_loss 1.7846299409866333, val_accuracy 0.7633333206176758\n",
            "Epoch: 94, train_loss 1.980119228363037, train_accuracy 0.7599999904632568, val_loss 1.7795560359954834, val_accuracy 0.7633333206176758\n",
            "Epoch: 95, train_loss 1.9586803913116455, train_accuracy 0.7419999837875366, val_loss 1.7747641801834106, val_accuracy 0.7641333341598511\n",
            "Epoch: 96, train_loss 2.000915765762329, train_accuracy 0.7639999985694885, val_loss 1.7698575258255005, val_accuracy 0.763866662979126\n",
            "Epoch: 97, train_loss 1.6642751693725586, train_accuracy 0.7419999837875366, val_loss 1.7646268606185913, val_accuracy 0.7642666697502136\n",
            "Epoch: 98, train_loss 1.5486079454421997, train_accuracy 0.7879999876022339, val_loss 1.7599564790725708, val_accuracy 0.7645333409309387\n",
            "Epoch: 99, train_loss 1.6777104139328003, train_accuracy 0.7760000228881836, val_loss 1.7549620866775513, val_accuracy 0.7639999985694885\n",
            "Epoch: 100, train_loss 1.5487689971923828, train_accuracy 0.7720000147819519, val_loss 1.7505768537521362, val_accuracy 0.7646666765213013\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "for epoch in range(1, epochs + 1):\n",
        "    for step, (batch_X, batch_Y) in enumerate(train_data.take(steps_per_epoch), 1):\n",
        "        run_optimizer(batch_X, batch_Y)\n",
        "\n",
        "    val_pred = model(valid_features)\n",
        "    val_loss = cross_entropy(val_pred, valid_labels)\n",
        "    val_acc = accuracy(val_pred, valid_labels)\n",
        "    train_pred = model(batch_X)\n",
        "    train_loss = cross_entropy(train_pred, batch_Y)\n",
        "    train_acc = accuracy(train_pred, batch_Y)\n",
        "    print(f\"Epoch: {epoch}, train_loss {train_loss}, train_accuracy {train_acc}, val_loss {val_loss}, val_accuracy {val_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "89964352-f865-4417-afa5-26bfef13f437",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89964352-f865-4417-afa5-26bfef13f437",
        "outputId": "7a91a422-0980-4e7a-fc48-976808a3f7f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test_loss 1.0562689304351807, Test_accuracy 0.8356000185012817\n"
          ]
        }
      ],
      "source": [
        "test_pred = model(test_features)\n",
        "test_loss = cross_entropy(test_pred, test_labels)\n",
        "test_acc = accuracy(test_pred, test_labels)\n",
        "print(f\"Test_loss {test_loss}, Test_accuracy {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbaa8601-7cee-442a-a667-c1e849ca20ce",
      "metadata": {
        "id": "cbaa8601-7cee-442a-a667-c1e849ca20ce"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}