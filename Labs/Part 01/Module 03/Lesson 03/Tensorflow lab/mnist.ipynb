{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6d08fe36-d4fa-4292-a54c-ccc02f156920",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d08fe36-d4fa-4292-a54c-ccc02f156920",
        "outputId": "5cb97f07-02bb-44c7-9d59-78c452b17f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data and modules loaded.\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Load the modules\n",
        "import pickle\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reload the data\n",
        "pickle_file = 'notMNIST.pickle'\n",
        "with open(pickle_file, 'rb') as f:\n",
        "  pickle_data = pickle.load(f)\n",
        "  train_features = pickle_data['train_dataset']\n",
        "  train_labels = pickle_data['train_labels']\n",
        "  valid_features = pickle_data['valid_dataset']\n",
        "  valid_labels = pickle_data['valid_labels']\n",
        "  test_features = pickle_data['test_dataset']\n",
        "  test_labels = pickle_data['test_labels']\n",
        "  del pickle_data  # Free up memory\n",
        "\n",
        "\n",
        "print('Data and modules loaded.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "DUVisuNJdFNG"
      },
      "id": "DUVisuNJdFNG"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e49cb51f-2576-43b1-a76a-fa642597976d",
      "metadata": {
        "id": "e49cb51f-2576-43b1-a76a-fa642597976d"
      },
      "outputs": [],
      "source": [
        "# Data has been normalized\n",
        "total_samples = len(train_features)\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.01\n",
        "num_output = 10\n",
        "epochs = 100\n",
        "batch_size = 1026\n",
        "steps_per_epoch = int(np.ceil(total_samples / batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2dd74ff5-8247-4304-a21e-227e1dc40857",
      "metadata": {
        "id": "2dd74ff5-8247-4304-a21e-227e1dc40857"
      },
      "outputs": [],
      "source": [
        "# Cleaning Data\n",
        "#valid_labels, test_labels = np.array(valid_labels, np.int64), np.array(test_labels, np.int64)\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_features, train_labels))\n",
        "val_features, test_features = np.array(valid_features, np.float32), np.array(test_features, np.float32)\n",
        "\n",
        "# Data has been normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "52a9b1dc-03ab-4628-ac52-544a0540979a",
      "metadata": {
        "id": "52a9b1dc-03ab-4628-ac52-544a0540979a"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "aa753673-88d7-4601-9dff-f9ade3381a24",
      "metadata": {
        "id": "aa753673-88d7-4601-9dff-f9ade3381a24"
      },
      "outputs": [],
      "source": [
        "features = train_features.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bdc4dec7-5917-4ff5-941e-3d82566529ac",
      "metadata": {
        "id": "bdc4dec7-5917-4ff5-941e-3d82566529ac"
      },
      "outputs": [],
      "source": [
        "W = tf.Variable(tf.random.normal([features, num_output], name=\"weights\"))\n",
        "B = tf.Variable(tf.random.normal([num_output], name=\"bias\"))\n",
        "\n",
        "optimizer = tf.optimizers.SGD(learning_rate)\n",
        "\n",
        "# Model\n",
        "def model(X):\n",
        "    return tf.nn.softmax(tf.add(tf.matmul(X, W), B))\n",
        "\n",
        "def cross_entropy(y_pred, y_true):\n",
        "    # It has been one-hot encoded before storing as pickle\n",
        "    #y_true = tf.one_hot(y_true, depth=num_output)\n",
        "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
        "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred), 1))\n",
        "\n",
        "def accuracy(y_pred, y_true):\n",
        "    if len(y_true.shape) > 1 and y_true.shape[1] > 1:\n",
        "        y_true = tf.argmax(y_true, axis=1)\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "def run_optimizer(X, Y):\n",
        "    with tf.GradientTape() as g:\n",
        "        logit = model(X)\n",
        "        loss = cross_entropy(logit, Y)\n",
        "\n",
        "    gradients = g.gradient(loss, [W, B])\n",
        "    optimizer.apply_gradients(zip(gradients, [W, B]))\n",
        "    return None\n",
        "\n",
        "def batch_data(X, Y, batch_size):\n",
        "    output_data = []\n",
        "    sample_size = len(X)\n",
        "    for step in range(0, sample_size, batch_size):\n",
        "        start = batch_size * step\n",
        "        end = batch_size + start\n",
        "        batch_X = X[start:end]\n",
        "        batch_Y = Y[start:end]\n",
        "        yield batch_X, batch_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "eed6bd8f-4bdc-4110-8cec-91ba172b3b55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eed6bd8f-4bdc-4110-8cec-91ba172b3b55",
        "outputId": "fefcb638-38a2-44b6-b05a-da6d83409dbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, train_loss 13.867289543151855, train_accuracy 0.0906432718038559, val_loss 13.864315032958984, val_accuracy 0.0868000015616417\n",
            "Epoch: 2, train_loss 11.787698745727539, train_accuracy 0.12670564651489258, val_loss 11.760003089904785, val_accuracy 0.12386666983366013\n",
            "Epoch: 3, train_loss 8.879352569580078, train_accuracy 0.2212475687265396, val_loss 9.143486022949219, val_accuracy 0.19480000436306\n",
            "Epoch: 4, train_loss 7.791680812835693, train_accuracy 0.2582845985889435, val_loss 7.66711950302124, val_accuracy 0.2669333219528198\n",
            "Epoch: 5, train_loss 6.456691741943359, train_accuracy 0.31676414608955383, val_loss 6.557403087615967, val_accuracy 0.31813332438468933\n",
            "Epoch: 6, train_loss 6.054911136627197, train_accuracy 0.35769981145858765, val_loss 5.7579216957092285, val_accuracy 0.36453333497047424\n",
            "Epoch: 7, train_loss 5.041998863220215, train_accuracy 0.4113060534000397, val_loss 5.134668350219727, val_accuracy 0.40253332257270813\n",
            "Epoch: 8, train_loss 4.567265033721924, train_accuracy 0.46198830008506775, val_loss 4.660482883453369, val_accuracy 0.43826666474342346\n",
            "Epoch: 9, train_loss 4.789481163024902, train_accuracy 0.4727095663547516, val_loss 4.30190372467041, val_accuracy 0.47173333168029785\n",
            "Epoch: 10, train_loss 3.9805080890655518, train_accuracy 0.5204678177833557, val_loss 4.0283379554748535, val_accuracy 0.5\n",
            "Epoch: 11, train_loss 3.9356279373168945, train_accuracy 0.5029239654541016, val_loss 3.815659284591675, val_accuracy 0.5231999754905701\n",
            "Epoch: 12, train_loss 3.625276565551758, train_accuracy 0.5233917832374573, val_loss 3.6460225582122803, val_accuracy 0.541866660118103\n",
            "Epoch: 13, train_loss 3.625339984893799, train_accuracy 0.5623781681060791, val_loss 3.508441925048828, val_accuracy 0.5589333176612854\n",
            "Epoch: 14, train_loss 3.420992851257324, train_accuracy 0.5779727101325989, val_loss 3.3939762115478516, val_accuracy 0.574400007724762\n",
            "Epoch: 15, train_loss 3.4165310859680176, train_accuracy 0.5896686315536499, val_loss 3.296675682067871, val_accuracy 0.5839999914169312\n",
            "Epoch: 16, train_loss 3.1582725048065186, train_accuracy 0.5857699513435364, val_loss 3.212167263031006, val_accuracy 0.5962666869163513\n",
            "Epoch: 17, train_loss 2.9692575931549072, train_accuracy 0.6159843802452087, val_loss 3.1384494304656982, val_accuracy 0.6058666706085205\n",
            "Epoch: 18, train_loss 3.4591856002807617, train_accuracy 0.5994151830673218, val_loss 3.073310613632202, val_accuracy 0.6172000169754028\n",
            "Epoch: 19, train_loss 2.868008852005005, train_accuracy 0.6306042671203613, val_loss 3.0142836570739746, val_accuracy 0.6240000128746033\n",
            "Epoch: 20, train_loss 2.824108123779297, train_accuracy 0.635477602481842, val_loss 2.9618544578552246, val_accuracy 0.6299999952316284\n",
            "Epoch: 21, train_loss 2.82084059715271, train_accuracy 0.6276803016662598, val_loss 2.913506507873535, val_accuracy 0.6353333592414856\n",
            "Epoch: 22, train_loss 2.6138064861297607, train_accuracy 0.6647173762321472, val_loss 2.869241237640381, val_accuracy 0.6413333415985107\n",
            "Epoch: 23, train_loss 2.6491448879241943, train_accuracy 0.6500974893569946, val_loss 2.828655958175659, val_accuracy 0.6462666392326355\n",
            "Epoch: 24, train_loss 2.7024805545806885, train_accuracy 0.6773878931999207, val_loss 2.7911338806152344, val_accuracy 0.6509333252906799\n",
            "Epoch: 25, train_loss 2.663816213607788, train_accuracy 0.6569200754165649, val_loss 2.756293296813965, val_accuracy 0.6553333401679993\n",
            "Epoch: 26, train_loss 2.7855992317199707, train_accuracy 0.6578947305679321, val_loss 2.7240967750549316, val_accuracy 0.6597333550453186\n",
            "Epoch: 27, train_loss 2.6482272148132324, train_accuracy 0.6569200754165649, val_loss 2.6934473514556885, val_accuracy 0.6634666919708252\n",
            "Epoch: 28, train_loss 2.6719515323638916, train_accuracy 0.6569200754165649, val_loss 2.6650476455688477, val_accuracy 0.6673333048820496\n",
            "Epoch: 29, train_loss 2.7273409366607666, train_accuracy 0.6578947305679321, val_loss 2.63830828666687, val_accuracy 0.6710666418075562\n",
            "Epoch: 30, train_loss 2.7565324306488037, train_accuracy 0.6510721445083618, val_loss 2.6128907203674316, val_accuracy 0.6741333603858948\n",
            "Epoch: 31, train_loss 2.5914058685302734, train_accuracy 0.6764132380485535, val_loss 2.5889577865600586, val_accuracy 0.6773333549499512\n",
            "Epoch: 32, train_loss 2.4898195266723633, train_accuracy 0.6754385828971863, val_loss 2.5661275386810303, val_accuracy 0.6793333292007446\n",
            "Epoch: 33, train_loss 2.428117275238037, train_accuracy 0.679337203502655, val_loss 2.544675827026367, val_accuracy 0.6809333562850952\n",
            "Epoch: 34, train_loss 2.3375155925750732, train_accuracy 0.696881115436554, val_loss 2.523634672164917, val_accuracy 0.6836000084877014\n",
            "Epoch: 35, train_loss 2.5018255710601807, train_accuracy 0.6871345043182373, val_loss 2.503620147705078, val_accuracy 0.6868000030517578\n",
            "Epoch: 36, train_loss 2.3983376026153564, train_accuracy 0.7066276669502258, val_loss 2.484823226928711, val_accuracy 0.6883999705314636\n",
            "Epoch: 37, train_loss 2.3667197227478027, train_accuracy 0.7115010023117065, val_loss 2.466813564300537, val_accuracy 0.6917333602905273\n",
            "Epoch: 38, train_loss 2.3317835330963135, train_accuracy 0.7066276669502258, val_loss 2.449183940887451, val_accuracy 0.6933333277702332\n",
            "Epoch: 39, train_loss 2.5347745418548584, train_accuracy 0.679337203502655, val_loss 2.4325783252716064, val_accuracy 0.6952000260353088\n",
            "Epoch: 40, train_loss 2.4743568897247314, train_accuracy 0.6988304257392883, val_loss 2.416260004043579, val_accuracy 0.6973333358764648\n",
            "Epoch: 41, train_loss 2.25407338142395, train_accuracy 0.7144249677658081, val_loss 2.400815963745117, val_accuracy 0.6993333101272583\n",
            "Epoch: 42, train_loss 2.1180579662323, train_accuracy 0.7280701994895935, val_loss 2.385627508163452, val_accuracy 0.7003999948501587\n",
            "Epoch: 43, train_loss 2.2440192699432373, train_accuracy 0.7085769772529602, val_loss 2.3711862564086914, val_accuracy 0.7013333439826965\n",
            "Epoch: 44, train_loss 2.2364418506622314, train_accuracy 0.7153996229171753, val_loss 2.35699200630188, val_accuracy 0.7029333114624023\n",
            "Epoch: 45, train_loss 2.236811399459839, train_accuracy 0.719298243522644, val_loss 2.3434131145477295, val_accuracy 0.7039999961853027\n",
            "Epoch: 46, train_loss 2.366712808609009, train_accuracy 0.6959064602851868, val_loss 2.3304152488708496, val_accuracy 0.7052000164985657\n",
            "Epoch: 47, train_loss 2.534409284591675, train_accuracy 0.6842105388641357, val_loss 2.3173043727874756, val_accuracy 0.7059999704360962\n",
            "Epoch: 48, train_loss 2.7690329551696777, train_accuracy 0.6773878931999207, val_loss 2.305018663406372, val_accuracy 0.7070666551589966\n",
            "Epoch: 49, train_loss 2.2792890071868896, train_accuracy 0.7095516324043274, val_loss 2.2932164669036865, val_accuracy 0.7084000110626221\n",
            "Epoch: 50, train_loss 2.059988498687744, train_accuracy 0.7329434752464294, val_loss 2.2816991806030273, val_accuracy 0.7101333141326904\n",
            "Epoch: 51, train_loss 2.4640398025512695, train_accuracy 0.7095516324043274, val_loss 2.2700541019439697, val_accuracy 0.7120000123977661\n",
            "Epoch: 52, train_loss 2.308181047439575, train_accuracy 0.7027290463447571, val_loss 2.2590889930725098, val_accuracy 0.712933361530304\n",
            "Epoch: 53, train_loss 2.434691905975342, train_accuracy 0.6929824352264404, val_loss 2.2483325004577637, val_accuracy 0.7146666646003723\n",
            "Epoch: 54, train_loss 2.089508295059204, train_accuracy 0.7407407164573669, val_loss 2.2382564544677734, val_accuracy 0.716533362865448\n",
            "Epoch: 55, train_loss 2.057485818862915, train_accuracy 0.7163742780685425, val_loss 2.2279269695281982, val_accuracy 0.7173333168029785\n",
            "Epoch: 56, train_loss 2.1636929512023926, train_accuracy 0.7163742780685425, val_loss 2.2179741859436035, val_accuracy 0.7177333235740662\n",
            "Epoch: 57, train_loss 2.1329619884490967, train_accuracy 0.7085769772529602, val_loss 2.2084455490112305, val_accuracy 0.7190666794776917\n",
            "Epoch: 58, train_loss 2.1397087574005127, train_accuracy 0.7329434752464294, val_loss 2.1990840435028076, val_accuracy 0.7197333574295044\n",
            "Epoch: 59, train_loss 2.5241918563842773, train_accuracy 0.696881115436554, val_loss 2.1896517276763916, val_accuracy 0.7201333045959473\n",
            "Epoch: 60, train_loss 2.3287384510040283, train_accuracy 0.7251461744308472, val_loss 2.1808276176452637, val_accuracy 0.72079998254776\n",
            "Epoch: 61, train_loss 2.159518003463745, train_accuracy 0.7115010023117065, val_loss 2.1721131801605225, val_accuracy 0.722000002861023\n",
            "Epoch: 62, train_loss 2.0871965885162354, train_accuracy 0.7261208295822144, val_loss 2.163841485977173, val_accuracy 0.7226666808128357\n",
            "Epoch: 63, train_loss 2.153853178024292, train_accuracy 0.7202728986740112, val_loss 2.155224561691284, val_accuracy 0.7232000231742859\n",
            "Epoch: 64, train_loss 2.103264331817627, train_accuracy 0.7261208295822144, val_loss 2.147294759750366, val_accuracy 0.7238666415214539\n",
            "Epoch: 65, train_loss 1.980547547340393, train_accuracy 0.7387914061546326, val_loss 2.1391689777374268, val_accuracy 0.724133312702179\n",
            "Epoch: 66, train_loss 2.1750450134277344, train_accuracy 0.72417151927948, val_loss 2.131176471710205, val_accuracy 0.7250666618347168\n",
            "Epoch: 67, train_loss 2.0846362113952637, train_accuracy 0.7407407164573669, val_loss 2.123697280883789, val_accuracy 0.7251999974250793\n",
            "Epoch: 68, train_loss 2.1451900005340576, train_accuracy 0.7348927855491638, val_loss 2.1159825325012207, val_accuracy 0.7261333465576172\n",
            "Epoch: 69, train_loss 2.251765251159668, train_accuracy 0.7329434752464294, val_loss 2.1089158058166504, val_accuracy 0.7266666889190674\n",
            "Epoch: 70, train_loss 1.9919838905334473, train_accuracy 0.7348927855491638, val_loss 2.1016135215759277, val_accuracy 0.7278666496276855\n",
            "Epoch: 71, train_loss 2.1490631103515625, train_accuracy 0.7309941649436951, val_loss 2.0945956707000732, val_accuracy 0.7286666631698608\n",
            "Epoch: 72, train_loss 2.1168761253356934, train_accuracy 0.7222222089767456, val_loss 2.087195634841919, val_accuracy 0.7286666631698608\n",
            "Epoch: 73, train_loss 2.2009308338165283, train_accuracy 0.7251461744308472, val_loss 2.080739736557007, val_accuracy 0.7293333411216736\n",
            "Epoch: 74, train_loss 2.003905773162842, train_accuracy 0.7202728986740112, val_loss 2.074084520339966, val_accuracy 0.7300000190734863\n",
            "Epoch: 75, train_loss 2.1364336013793945, train_accuracy 0.7319688200950623, val_loss 2.0673911571502686, val_accuracy 0.730400025844574\n",
            "Epoch: 76, train_loss 2.1935296058654785, train_accuracy 0.7212475538253784, val_loss 2.0610859394073486, val_accuracy 0.7310666441917419\n",
            "Epoch: 77, train_loss 2.194692373275757, train_accuracy 0.7251461744308472, val_loss 2.0545637607574463, val_accuracy 0.731333315372467\n",
            "Epoch: 78, train_loss 1.8758742809295654, train_accuracy 0.752436637878418, val_loss 2.0482828617095947, val_accuracy 0.7322666645050049\n",
            "Epoch: 79, train_loss 2.147611379623413, train_accuracy 0.72417151927948, val_loss 2.042005777359009, val_accuracy 0.73253333568573\n",
            "Epoch: 80, train_loss 1.918931245803833, train_accuracy 0.7465887069702148, val_loss 2.035959243774414, val_accuracy 0.7329333424568176\n",
            "Epoch: 81, train_loss 1.8968605995178223, train_accuracy 0.7436647415161133, val_loss 2.0297656059265137, val_accuracy 0.7333333492279053\n",
            "Epoch: 82, train_loss 2.0981311798095703, train_accuracy 0.7436647415161133, val_loss 2.0240185260772705, val_accuracy 0.7337333559989929\n",
            "Epoch: 83, train_loss 2.101287841796875, train_accuracy 0.7300195097923279, val_loss 2.0182955265045166, val_accuracy 0.7349333167076111\n",
            "Epoch: 84, train_loss 1.9861971139907837, train_accuracy 0.7270955443382263, val_loss 2.012504816055298, val_accuracy 0.7343999743461609\n",
            "Epoch: 85, train_loss 2.054893732070923, train_accuracy 0.7348927855491638, val_loss 2.0066869258880615, val_accuracy 0.7355999946594238\n",
            "Epoch: 86, train_loss 2.019845962524414, train_accuracy 0.7300195097923279, val_loss 2.0010030269622803, val_accuracy 0.7357333302497864\n",
            "Epoch: 87, train_loss 1.829787254333496, train_accuracy 0.7592592835426331, val_loss 1.9955495595932007, val_accuracy 0.7362666726112366\n",
            "Epoch: 88, train_loss 2.066868543624878, train_accuracy 0.7417153716087341, val_loss 1.9899665117263794, val_accuracy 0.7368000149726868\n",
            "Epoch: 89, train_loss 1.8483670949935913, train_accuracy 0.7514619827270508, val_loss 1.9847463369369507, val_accuracy 0.7372000217437744\n",
            "Epoch: 90, train_loss 1.7088395357131958, train_accuracy 0.7699804902076721, val_loss 1.9792042970657349, val_accuracy 0.7379999756813049\n",
            "Epoch: 91, train_loss 1.923171043395996, train_accuracy 0.7495126724243164, val_loss 1.9739359617233276, val_accuracy 0.7379999756813049\n",
            "Epoch: 92, train_loss 2.033038854598999, train_accuracy 0.7436647415161133, val_loss 1.968896746635437, val_accuracy 0.7379999756813049\n",
            "Epoch: 93, train_loss 2.0380959510803223, train_accuracy 0.7339181303977966, val_loss 1.963965892791748, val_accuracy 0.7381333112716675\n",
            "Epoch: 94, train_loss 2.0379793643951416, train_accuracy 0.7417153716087341, val_loss 1.958810806274414, val_accuracy 0.7390666604042053\n",
            "Epoch: 95, train_loss 1.9720162153244019, train_accuracy 0.7300195097923279, val_loss 1.9539180994033813, val_accuracy 0.7391999959945679\n",
            "Epoch: 96, train_loss 1.8572125434875488, train_accuracy 0.7446393966674805, val_loss 1.9494030475616455, val_accuracy 0.7400000095367432\n",
            "Epoch: 97, train_loss 2.106611967086792, train_accuracy 0.7251461744308472, val_loss 1.9444881677627563, val_accuracy 0.7401333451271057\n",
            "Epoch: 98, train_loss 2.059709072113037, train_accuracy 0.747563362121582, val_loss 1.9395500421524048, val_accuracy 0.7408000230789185\n",
            "Epoch: 99, train_loss 1.7736003398895264, train_accuracy 0.747563362121582, val_loss 1.9347221851348877, val_accuracy 0.7413333058357239\n",
            "Epoch: 100, train_loss 1.8766608238220215, train_accuracy 0.7534112930297852, val_loss 1.9303086996078491, val_accuracy 0.741599977016449\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "for epoch in range(1, epochs + 1):\n",
        "    for step, (batch_X, batch_Y) in enumerate(train_data.take(steps_per_epoch), 1):\n",
        "        run_optimizer(batch_X, batch_Y)\n",
        "\n",
        "    val_pred = model(valid_features)\n",
        "    val_loss = cross_entropy(val_pred, valid_labels)\n",
        "    val_acc = accuracy(val_pred, valid_labels)\n",
        "    train_pred = model(batch_X)\n",
        "    train_loss = cross_entropy(train_pred, batch_Y)\n",
        "    train_acc = accuracy(train_pred, batch_Y)\n",
        "    print(f\"Epoch: {epoch}, train_loss {train_loss}, train_accuracy {train_acc}, val_loss {val_loss}, val_accuracy {val_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "89964352-f865-4417-afa5-26bfef13f437",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89964352-f865-4417-afa5-26bfef13f437",
        "outputId": "1854837a-de9b-4955-f35e-9f3f9c392ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test_loss 1.16489839553833, Test_accuracy 0.826200008392334\n"
          ]
        }
      ],
      "source": [
        "test_pred = model(test_features)\n",
        "test_loss = cross_entropy(test_pred, test_labels)\n",
        "test_acc = accuracy(test_pred, test_labels)\n",
        "print(f\"Test_loss {test_loss}, Test_accuracy {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbaa8601-7cee-442a-a667-c1e849ca20ce",
      "metadata": {
        "id": "cbaa8601-7cee-442a-a667-c1e849ca20ce"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
