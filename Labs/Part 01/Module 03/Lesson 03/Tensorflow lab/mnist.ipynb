{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d08fe36-d4fa-4292-a54c-ccc02f156920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and modules loaded.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load the modules\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reload the data\n",
    "pickle_file = 'notMNIST.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  train_features = pickle_data['train_dataset']\n",
    "  train_labels = pickle_data['train_labels']\n",
    "  valid_features = pickle_data['valid_dataset']\n",
    "  valid_labels = pickle_data['valid_labels']\n",
    "  test_features = pickle_data['test_dataset']\n",
    "  test_labels = pickle_data['test_labels']\n",
    "  del pickle_data  # Free up memory\n",
    "\n",
    "\n",
    "print('Data and modules loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e49cb51f-2576-43b1-a76a-fa642597976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data has been normalized \n",
    "total_samples = len(train_features)\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.008\n",
    "num_output = 10\n",
    "epochs = 100\n",
    "batch_size = 500\n",
    "steps_per_epoch = int(np.ceil(total_samples / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dd74ff5-8247-4304-a21e-227e1dc40857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Data\n",
    "#valid_labels, test_labels = np.array(valid_labels, np.int64), np.array(test_labels, np.int64)\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_features, train_labels))\n",
    "val_features, test_features = np.array(valid_features, np.float32), np.array(test_features, np.float32)\n",
    "\n",
    "# Data has been normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52a9b1dc-03ab-4628-ac52-544a0540979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa753673-88d7-4601-9dff-f9ade3381a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdc4dec7-5917-4ff5-941e-3d82566529ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.normal([features, num_output], name=\"weights1\"))\n",
    "B = tf.Variable(tf.zeros([num_output], name=\"bias1\"))\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "# Model\n",
    "class MyModel(tf.Module):\n",
    "    def __call__(self, X):\n",
    "        return tf.nn.softmax(tf.add(tf.matmul(X, W), B))\n",
    "\n",
    "def cross_entropy(y_pred, y_true):\n",
    "    # It has been one-hot encoded before storing as pickle\n",
    "    #y_true = tf.one_hot(y_true, depth=num_output) \n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred), 1))\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    if len(y_true.shape) > 1 and y_true.shape[1] > 1:\n",
    "        y_true = tf.argmax(y_true, axis=1)\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "def run_optimizer(X, Y):\n",
    "    with tf.GradientTape() as g:\n",
    "        logit = model(X)\n",
    "        loss = cross_entropy(logit, Y)\n",
    "\n",
    "    gradients = g.gradient(loss, [W, B])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, B]))\n",
    "    return None\n",
    "\n",
    "def batch_data(X, Y, batch_size):\n",
    "    output_data = []\n",
    "    sample_size = len(X)\n",
    "    for step in range(0, sample_size, batch_size):\n",
    "        start = batch_size * step\n",
    "        end = batch_size + start\n",
    "        batch_X = X[start:end]\n",
    "        batch_Y = Y[start:end]\n",
    "        yield batch_X, batch_Y\n",
    "\n",
    "model=MyModel()\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(model = model)\n",
    "checkpoint.save(\"./checkpoints/mymodel\")\n",
    "manager = tf.train.CheckpointManager(checkpoint, \"./checkpoints\", max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eed6bd8f-4bdc-4110-8cec-91ba172b3b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train_loss 12.338140487670898, train_accuracy 0.21799999475479126, val_loss 12.678192138671875, val_accuracy 0.1891999989748001\n",
      "Epoch: 2, train_loss 11.177257537841797, train_accuracy 0.25200000405311584, val_loss 11.251325607299805, val_accuracy 0.23520000278949738\n",
      "Epoch: 3, train_loss 9.799777030944824, train_accuracy 0.2619999945163727, val_loss 9.643571853637695, val_accuracy 0.26306667923927307\n",
      "Epoch: 4, train_loss 8.577306747436523, train_accuracy 0.3019999861717224, val_loss 8.573391914367676, val_accuracy 0.2939999997615814\n",
      "Epoch: 5, train_loss 7.493995666503906, train_accuracy 0.33399999141693115, val_loss 7.161098003387451, val_accuracy 0.3202666640281677\n",
      "Epoch: 6, train_loss 6.142388343811035, train_accuracy 0.38999998569488525, val_loss 6.284374713897705, val_accuracy 0.3898666799068451\n",
      "Epoch: 7, train_loss 6.32255220413208, train_accuracy 0.45399999618530273, val_loss 5.756913661956787, val_accuracy 0.4413333237171173\n",
      "Epoch: 8, train_loss 5.473896503448486, train_accuracy 0.4560000002384186, val_loss 5.414018154144287, val_accuracy 0.48106667399406433\n",
      "Epoch: 9, train_loss 4.842469215393066, train_accuracy 0.527999997138977, val_loss 5.1732707023620605, val_accuracy 0.5094666481018066\n",
      "Epoch: 10, train_loss 4.797577381134033, train_accuracy 0.5239999890327454, val_loss 4.995573043823242, val_accuracy 0.5321333408355713\n",
      "Epoch: 11, train_loss 4.707598686218262, train_accuracy 0.527999997138977, val_loss 4.85812520980835, val_accuracy 0.5496000051498413\n",
      "Epoch: 12, train_loss 4.503990650177002, train_accuracy 0.5879999995231628, val_loss 4.749143600463867, val_accuracy 0.5629333257675171\n",
      "Epoch: 13, train_loss 4.715231418609619, train_accuracy 0.5860000252723694, val_loss 4.659034729003906, val_accuracy 0.5766666531562805\n",
      "Epoch: 14, train_loss 4.252328872680664, train_accuracy 0.6159999966621399, val_loss 4.583601951599121, val_accuracy 0.5869333148002625\n",
      "Epoch: 15, train_loss 4.267886638641357, train_accuracy 0.6159999966621399, val_loss 4.519128322601318, val_accuracy 0.5965333580970764\n",
      "Epoch: 16, train_loss 4.066821098327637, train_accuracy 0.6019999980926514, val_loss 4.46278190612793, val_accuracy 0.6042666435241699\n",
      "Epoch: 17, train_loss 4.901900768280029, train_accuracy 0.5860000252723694, val_loss 4.412569999694824, val_accuracy 0.611466646194458\n",
      "Epoch: 18, train_loss 4.472736358642578, train_accuracy 0.6159999966621399, val_loss 4.367727756500244, val_accuracy 0.6173333525657654\n",
      "Epoch: 19, train_loss 4.406411170959473, train_accuracy 0.5920000076293945, val_loss 4.327180862426758, val_accuracy 0.6222666501998901\n",
      "Epoch: 20, train_loss 4.264439582824707, train_accuracy 0.6259999871253967, val_loss 4.290887355804443, val_accuracy 0.6251999735832214\n",
      "Epoch: 21, train_loss 4.497006416320801, train_accuracy 0.5860000252723694, val_loss 4.257072448730469, val_accuracy 0.6274666786193848\n",
      "Epoch: 22, train_loss 4.3586859703063965, train_accuracy 0.6340000033378601, val_loss 4.225954532623291, val_accuracy 0.628933310508728\n",
      "Epoch: 23, train_loss 4.005146026611328, train_accuracy 0.6320000290870667, val_loss 4.196584701538086, val_accuracy 0.6333333253860474\n",
      "Epoch: 24, train_loss 4.581331253051758, train_accuracy 0.6100000143051147, val_loss 4.169219493865967, val_accuracy 0.6357333064079285\n",
      "Epoch: 25, train_loss 4.46816873550415, train_accuracy 0.6299999952316284, val_loss 4.143401145935059, val_accuracy 0.6384000182151794\n",
      "Epoch: 26, train_loss 4.153124809265137, train_accuracy 0.6240000128746033, val_loss 4.118330001831055, val_accuracy 0.6398666501045227\n",
      "Epoch: 27, train_loss 4.25076961517334, train_accuracy 0.6200000047683716, val_loss 4.0945634841918945, val_accuracy 0.6424000263214111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 09:00:38.776289: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, train_loss 4.077287197113037, train_accuracy 0.6579999923706055, val_loss 4.071807384490967, val_accuracy 0.6446666717529297\n",
      "Epoch: 29, train_loss 3.767143726348877, train_accuracy 0.6740000247955322, val_loss 4.0494866371154785, val_accuracy 0.646133303642273\n",
      "Epoch: 30, train_loss 3.626960515975952, train_accuracy 0.6579999923706055, val_loss 4.027705669403076, val_accuracy 0.6478666663169861\n",
      "Epoch: 31, train_loss 4.343687057495117, train_accuracy 0.6380000114440918, val_loss 4.0054731369018555, val_accuracy 0.6489333510398865\n",
      "Epoch: 32, train_loss 3.6914846897125244, train_accuracy 0.6520000100135803, val_loss 3.983588218688965, val_accuracy 0.6510666608810425\n",
      "Epoch: 33, train_loss 3.7999229431152344, train_accuracy 0.6480000019073486, val_loss 3.9614980220794678, val_accuracy 0.653333306312561\n",
      "Epoch: 34, train_loss 3.828500270843506, train_accuracy 0.6700000166893005, val_loss 3.9392876625061035, val_accuracy 0.6553333401679993\n",
      "Epoch: 35, train_loss 3.813655138015747, train_accuracy 0.6480000019073486, val_loss 3.9165186882019043, val_accuracy 0.6564000248908997\n",
      "Epoch: 36, train_loss 4.0981621742248535, train_accuracy 0.6240000128746033, val_loss 3.894190549850464, val_accuracy 0.6569333076477051\n",
      "Epoch: 37, train_loss 3.8436245918273926, train_accuracy 0.656000018119812, val_loss 3.865051507949829, val_accuracy 0.6570666432380676\n",
      "Epoch: 38, train_loss 3.6176419258117676, train_accuracy 0.6439999938011169, val_loss 3.7329607009887695, val_accuracy 0.6462666392326355\n",
      "Epoch: 39, train_loss 4.181035041809082, train_accuracy 0.5720000267028809, val_loss 3.2985024452209473, val_accuracy 0.6234666705131531\n",
      "Epoch: 40, train_loss 2.53464674949646, train_accuracy 0.6679999828338623, val_loss 2.664618492126465, val_accuracy 0.6598666906356812\n",
      "Epoch: 41, train_loss 2.1400644779205322, train_accuracy 0.7099999785423279, val_loss 2.40370512008667, val_accuracy 0.6910666823387146\n",
      "Epoch: 42, train_loss 2.053339958190918, train_accuracy 0.7360000014305115, val_loss 2.314866304397583, val_accuracy 0.7039999961853027\n",
      "Epoch: 43, train_loss 2.628486156463623, train_accuracy 0.6859999895095825, val_loss 2.267542600631714, val_accuracy 0.7111999988555908\n",
      "Epoch: 44, train_loss 2.011869430541992, train_accuracy 0.7400000095367432, val_loss 2.2349934577941895, val_accuracy 0.716533362865448\n",
      "Epoch: 45, train_loss 2.1767361164093018, train_accuracy 0.734000027179718, val_loss 2.20965313911438, val_accuracy 0.7200000286102295\n",
      "Epoch: 46, train_loss 2.4033541679382324, train_accuracy 0.6980000138282776, val_loss 2.188746452331543, val_accuracy 0.7211999893188477\n",
      "Epoch: 47, train_loss 2.0252935886383057, train_accuracy 0.722000002861023, val_loss 2.1701366901397705, val_accuracy 0.7230666875839233\n",
      "Epoch: 48, train_loss 2.193608045578003, train_accuracy 0.7239999771118164, val_loss 2.152864694595337, val_accuracy 0.725600004196167\n",
      "Epoch: 49, train_loss 1.8599133491516113, train_accuracy 0.7459999918937683, val_loss 2.1367385387420654, val_accuracy 0.7262666821479797\n",
      "Epoch: 50, train_loss 2.0012495517730713, train_accuracy 0.7519999742507935, val_loss 2.1221656799316406, val_accuracy 0.7281333208084106\n",
      "Epoch: 51, train_loss 2.050980806350708, train_accuracy 0.734000027179718, val_loss 2.108067035675049, val_accuracy 0.7297333478927612\n",
      "Epoch: 52, train_loss 2.124246597290039, train_accuracy 0.722000002861023, val_loss 2.09450626373291, val_accuracy 0.7315999865531921\n",
      "Epoch: 53, train_loss 2.2788708209991455, train_accuracy 0.7080000042915344, val_loss 2.0816140174865723, val_accuracy 0.7337333559989929\n",
      "Epoch: 54, train_loss 2.248915433883667, train_accuracy 0.7319999933242798, val_loss 2.069398880004883, val_accuracy 0.7347999811172485\n",
      "Epoch: 55, train_loss 2.37367582321167, train_accuracy 0.7160000205039978, val_loss 2.05729079246521, val_accuracy 0.7347999811172485\n",
      "Epoch: 56, train_loss 1.8134759664535522, train_accuracy 0.765999972820282, val_loss 2.0460267066955566, val_accuracy 0.7362666726112366\n",
      "Epoch: 57, train_loss 2.128629446029663, train_accuracy 0.7360000014305115, val_loss 2.0346264839172363, val_accuracy 0.7368000149726868\n",
      "Epoch: 58, train_loss 1.9143120050430298, train_accuracy 0.7540000081062317, val_loss 2.023693323135376, val_accuracy 0.7378666400909424\n",
      "Epoch: 59, train_loss 1.9503631591796875, train_accuracy 0.75, val_loss 2.0131630897521973, val_accuracy 0.7370666861534119\n",
      "Epoch: 60, train_loss 2.1870357990264893, train_accuracy 0.7239999771118164, val_loss 2.0027015209198, val_accuracy 0.7377333045005798\n",
      "Epoch: 61, train_loss 1.8226885795593262, train_accuracy 0.7480000257492065, val_loss 1.9924112558364868, val_accuracy 0.7378666400909424\n",
      "Epoch: 62, train_loss 1.9694414138793945, train_accuracy 0.7559999823570251, val_loss 1.9824097156524658, val_accuracy 0.7387999892234802\n",
      "Epoch: 63, train_loss 1.8213762044906616, train_accuracy 0.7379999756813049, val_loss 1.9729454517364502, val_accuracy 0.7390666604042053\n",
      "Epoch: 64, train_loss 1.905045986175537, train_accuracy 0.75, val_loss 1.9634736776351929, val_accuracy 0.7401333451271057\n",
      "Epoch: 65, train_loss 2.076204299926758, train_accuracy 0.722000002861023, val_loss 1.954087495803833, val_accuracy 0.7400000095367432\n",
      "Epoch: 66, train_loss 1.7675470113754272, train_accuracy 0.7419999837875366, val_loss 1.945088267326355, val_accuracy 0.7406666874885559\n",
      "Epoch: 67, train_loss 1.8288211822509766, train_accuracy 0.7440000176429749, val_loss 1.9363020658493042, val_accuracy 0.741599977016449\n",
      "Epoch: 68, train_loss 1.7517781257629395, train_accuracy 0.7900000214576721, val_loss 1.9277163743972778, val_accuracy 0.7418666481971741\n",
      "Epoch: 69, train_loss 2.057399034500122, train_accuracy 0.7400000095367432, val_loss 1.9191851615905762, val_accuracy 0.7427999973297119\n",
      "Epoch: 70, train_loss 1.718348741531372, train_accuracy 0.7580000162124634, val_loss 1.91071355342865, val_accuracy 0.743066668510437\n",
      "Epoch: 71, train_loss 1.8719297647476196, train_accuracy 0.7559999823570251, val_loss 1.9026380777359009, val_accuracy 0.7434666752815247\n",
      "Epoch: 72, train_loss 1.9368032217025757, train_accuracy 0.7540000081062317, val_loss 1.8947627544403076, val_accuracy 0.7437333464622498\n",
      "Epoch: 73, train_loss 2.000147581100464, train_accuracy 0.734000027179718, val_loss 1.8868423700332642, val_accuracy 0.7437333464622498\n",
      "Epoch: 74, train_loss 1.9592710733413696, train_accuracy 0.7540000081062317, val_loss 1.879421353340149, val_accuracy 0.744533360004425\n",
      "Epoch: 75, train_loss 2.1429474353790283, train_accuracy 0.75, val_loss 1.8715990781784058, val_accuracy 0.7446666955947876\n",
      "Epoch: 76, train_loss 2.1854865550994873, train_accuracy 0.7459999918937683, val_loss 1.864231824874878, val_accuracy 0.745199978351593\n",
      "Epoch: 77, train_loss 1.9316291809082031, train_accuracy 0.7440000176429749, val_loss 1.8570425510406494, val_accuracy 0.7454666495323181\n",
      "Epoch: 78, train_loss 2.3032772541046143, train_accuracy 0.7279999852180481, val_loss 1.8499689102172852, val_accuracy 0.7458666563034058\n",
      "Epoch: 79, train_loss 1.7914265394210815, train_accuracy 0.7820000052452087, val_loss 1.8431737422943115, val_accuracy 0.7468000054359436\n",
      "Epoch: 80, train_loss 1.9235615730285645, train_accuracy 0.7459999918937683, val_loss 1.8360344171524048, val_accuracy 0.7468000054359436\n",
      "Epoch: 81, train_loss 1.6749615669250488, train_accuracy 0.7860000133514404, val_loss 1.8294697999954224, val_accuracy 0.7473333477973938\n",
      "Epoch: 82, train_loss 1.9674636125564575, train_accuracy 0.7680000066757202, val_loss 1.8224819898605347, val_accuracy 0.7474666833877563\n",
      "Epoch: 83, train_loss 1.8287949562072754, train_accuracy 0.7459999918937683, val_loss 1.8155436515808105, val_accuracy 0.7476000189781189\n",
      "Epoch: 84, train_loss 1.92607843875885, train_accuracy 0.7639999985694885, val_loss 1.809128999710083, val_accuracy 0.7474666833877563\n",
      "Epoch: 85, train_loss 1.967678427696228, train_accuracy 0.7459999918937683, val_loss 1.8025809526443481, val_accuracy 0.7480000257492065\n",
      "Epoch: 86, train_loss 1.6954832077026367, train_accuracy 0.7639999985694885, val_loss 1.7965505123138428, val_accuracy 0.7491999864578247\n",
      "Epoch: 87, train_loss 1.9510188102722168, train_accuracy 0.7459999918937683, val_loss 1.7897899150848389, val_accuracy 0.7498666644096375\n",
      "Epoch: 88, train_loss 2.0775539875030518, train_accuracy 0.7279999852180481, val_loss 1.7841318845748901, val_accuracy 0.7504000067710876\n",
      "Epoch: 89, train_loss 1.7186335325241089, train_accuracy 0.7540000081062317, val_loss 1.7777615785598755, val_accuracy 0.7504000067710876\n",
      "Epoch: 90, train_loss 1.5973254442214966, train_accuracy 0.7720000147819519, val_loss 1.771679401397705, val_accuracy 0.7508000135421753\n",
      "Epoch: 91, train_loss 1.65559720993042, train_accuracy 0.7739999890327454, val_loss 1.7656450271606445, val_accuracy 0.7509333491325378\n",
      "Epoch: 92, train_loss 1.8878241777420044, train_accuracy 0.7540000081062317, val_loss 1.7599915266036987, val_accuracy 0.7510666847229004\n",
      "Epoch: 93, train_loss 1.78742253780365, train_accuracy 0.7360000014305115, val_loss 1.7540779113769531, val_accuracy 0.7513333559036255\n",
      "Epoch: 94, train_loss 1.5435415506362915, train_accuracy 0.7760000228881836, val_loss 1.7486733198165894, val_accuracy 0.7509333491325378\n",
      "Epoch: 95, train_loss 1.775084137916565, train_accuracy 0.7480000257492065, val_loss 1.7429218292236328, val_accuracy 0.7517333626747131\n",
      "Epoch: 96, train_loss 1.9264600276947021, train_accuracy 0.7419999837875366, val_loss 1.7373031377792358, val_accuracy 0.7517333626747131\n",
      "Epoch: 97, train_loss 1.8119126558303833, train_accuracy 0.7580000162124634, val_loss 1.7319190502166748, val_accuracy 0.7519999742507935\n",
      "Epoch: 98, train_loss 1.6560792922973633, train_accuracy 0.765999972820282, val_loss 1.7264610528945923, val_accuracy 0.7519999742507935\n",
      "Epoch: 99, train_loss 1.5782655477523804, train_accuracy 0.7559999823570251, val_loss 1.7211674451828003, val_accuracy 0.752133309841156\n",
      "Epoch: 100, train_loss 2.055173873901367, train_accuracy 0.7379999756813049, val_loss 1.7156258821487427, val_accuracy 0.7522666454315186\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, (batch_X, batch_Y) in enumerate(train_data.take(steps_per_epoch), 1):\n",
    "        run_optimizer(batch_X, batch_Y)\n",
    "\n",
    "    val_pred = model(valid_features)\n",
    "    val_loss = cross_entropy(val_pred, valid_labels)\n",
    "    val_acc = accuracy(val_pred, valid_labels)\n",
    "    train_pred = model(batch_X)\n",
    "    train_loss = cross_entropy(train_pred, batch_Y)\n",
    "    train_acc = accuracy(train_pred, batch_Y)\n",
    "    manager.save()\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, train_loss {train_loss}, train_accuracy {train_acc}, val_loss {val_loss}, val_accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89964352-f865-4417-afa5-26bfef13f437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss 1.0521560907363892, Test_accuracy 0.8331999778747559\n"
     ]
    }
   ],
   "source": [
    "test_pred = model(test_features)\n",
    "test_loss = cross_entropy(test_pred, test_labels)\n",
    "test_acc = accuracy(test_pred, test_labels)\n",
    "print(f\"Test_loss {test_loss}, Test_accuracy {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa8601-7cee-442a-a667-c1e849ca20ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
